# Metis Data Science Bootcamp | Project 4

## Analyzing the Impact of Twitter Bots on the U.S. Presidential Election's Political Discourse 

Duration: 3 weeks

(in progress)

![Biden vs. Trump](https://github.com/edubu2/metis-project4/blob/main/etc/biden_trump_photo.jpg)
___
## Tech Stack

* Python3 Libraries
  * `Twitter bot classification model` from Chris Doenlen
    * https://github.com/scrapfishies/twitter-bot-detection
    * model contained in `/code/pickle/bot_model.pick`
      * can also be generated by forking & cloning the repository
  * `numpy` & `pandas`
  * `matplotlib` & `seaborn`
  * `scikit-learn`
    * Count and TF/IDF vectorizers
    * NMF, LDA, LSA clustering algorithms
  * `Twint` (Twitter scraping library)
    * No limits, however the module seems to be loosely maintained and the results can be buggy.
  * `Tweepy` (Twitter's official API)
    * **NOTE**: Tweepy requires a Twitter Developer API key. There is a [request process](https://developer.twitter.com/en) that can take a couple of days.
    * Requests are limited to 300 per 15 minutes, so querying large amounts of data is also time consuming.
  * `NLTK` (natural language toolkit)
    * `tweet_tokenize`, `WordLemmatizer`, stop words, English word list


* Other tools
  * `GCP` Compute Engine (for VMs)
    * `Filezilla`
  * `Tableau` Public Edition (for data visualization)
___
## Navigating This Repository

The file structure is explained as follows:

* `code/`: contains all code used for the project. If you are planning on reproducing locally, run the below notebooks (in order). You may need to create empty directories and install any necessary libraries along the way.
  * `scrape_bot_probas.ipynb`:
    * Use
  * `get_tweets.ipynb`: this notebook uses the `Twint` Python library to pull all tweets from Oct 1 - Nov 2, 2020 that contain the words `trump` and `biden`
  * `aggregate_tweets.ipynb`: combines the .csv files generated from `clean_tweets.ipynb` into one DataFrame
  * `clean_tweets.ipynb`: pre-processes tweets (stop word removal, n-grams, lemmatization)
  * `topic_modeling.ipynb`: implement TF/IDF\* and NMF\*\* algorithms in order to create 30 topic clusters 
    * \* Term Frequency * Inverse Document Frequency
    * \*\* Non-Negative Matrix Factorization
  * `topic_naming.ipynb`: analysis of our topic clusters & assigning names to each cluster
  * `bots.ipynb`: pulls user-level bot probabilities into the tweets data and analyze the results
    * data visualization with `matplotlib` and `seaborn` here

* `data/` contains the raw data files generated from the various files in `code/`
* `etc/` contains miscellaneous project resources

___
## Topics

