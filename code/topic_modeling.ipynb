{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stop\n",
    "from stop_words import stop_words as custom_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = list(nltk_stop.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"pickle/n2_tokenized_eff.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eligible-zoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13580</th>\n",
       "      <td>1323410823516246018</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:45:02</td>\n",
       "      <td>285108919</td>\n",
       "      <td>booking_it_fast</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Hey @JoeBiden, my kindergartner has some advice for you.  https://t.co/XZ4tm4kUp0</td>\n",
       "      <td>hey kindergartner advice</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43978</th>\n",
       "      <td>1323402012810240005</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:10:02</td>\n",
       "      <td>23838260</td>\n",
       "      <td>ethannichtern</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@traceydurning They need a story, that's not really true in the aggregate. @FiveThirtyEight has the odds of a Biden victory higher than last week (I only check weekly).</td>\n",
       "      <td>story true odds victory higher week check weekly</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83015</th>\n",
       "      <td>1323400588189720576</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:04:22</td>\n",
       "      <td>2259760956</td>\n",
       "      <td>kayla_hinty</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the fact that trumpies are planning attacks on bipoc and members of the lgbtq+ community is very very telling of Donald Trump’s presidency and what he represents.</td>\n",
       "      <td>fact attack member community presidency</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id       date      time     user_id         username  \\\n",
       "13580  1323410823516246018 2020-11-02  23:45:02   285108919  booking_it_fast   \n",
       "43978  1323402012810240005 2020-11-02  23:10:02    23838260    ethannichtern   \n",
       "83015  1323400588189720576 2020-11-02  23:04:22  2259760956      kayla_hinty   \n",
       "\n",
       "      hashtags  trump  biden  \\\n",
       "13580       []  False   True   \n",
       "43978       []  False   True   \n",
       "83015       []   True  False   \n",
       "\n",
       "                                                                                                                                                                       original  \\\n",
       "13580                                                                                         Hey @JoeBiden, my kindergartner has some advice for you.  https://t.co/XZ4tm4kUp0   \n",
       "43978  @traceydurning They need a story, that's not really true in the aggregate. @FiveThirtyEight has the odds of a Biden victory higher than last week (I only check weekly).   \n",
       "83015        the fact that trumpies are planning attacks on bipoc and members of the lgbtq+ community is very very telling of Donald Trump’s presidency and what he represents.   \n",
       "\n",
       "                                                  tweet  num_tokens  \n",
       "13580                          hey kindergartner advice           3  \n",
       "43978  story true odds victory higher week check weekly           8  \n",
       "83015           fact attack member community presidency           5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-origin",
   "metadata": {},
   "source": [
    "## TF/IDF Vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "female-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = custom_stop + nltk_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conventional-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tfidf = TfidfVectorizer(max_df=0.16, min_df=0.0002, stop_words=stop_words)\n",
    "doc_word_ti = v_tfidf.fit_transform(data.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reliance",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "instructional-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (96000, 12)\n",
      "Number of iterations used: 137\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=12, init='nndsvda')\n",
    "doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "print(f\"Shape: {doc_topic.shape}\")\n",
    "print(f\"Number of iterations used: {nmf_model.n_iter_}\")\n",
    "\n",
    "# pd.DataFrame(doc_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-commonwealth",
   "metadata": {},
   "source": [
    "From lecture: The **topic_word** matrix shows us the 2 resulting topics, and the terms that are associated with each topic. By looking at the words below, we can figure out what the topics are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surface-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['vote',\n",
       "  'electionday',\n",
       "  'electoral',\n",
       "  'party',\n",
       "  'ballot',\n",
       "  'cast',\n",
       "  'attorneygeneral',\n",
       "  'democracy',\n",
       "  'voter',\n",
       "  'mail',\n",
       "  'voice',\n",
       "  'bidenharris',\n",
       "  'victory',\n",
       "  'nation',\n",
       "  'electoralcollege',\n",
       "  'voteblue',\n",
       "  'counting',\n",
       "  'life',\n",
       "  'enough',\n",
       "  'govote',\n",
       "  'line',\n",
       "  'remember',\n",
       "  'future',\n",
       "  'former',\n",
       "  'change',\n",
       "  'black',\n",
       "  'blue',\n",
       "  'steal',\n",
       "  'may',\n",
       "  'save'],\n",
       " ['barackobama',\n",
       "  'cnn',\n",
       "  'steal',\n",
       "  'speech',\n",
       "  'hillaryclinton',\n",
       "  'pointer',\n",
       "  'hammer',\n",
       "  'sweet',\n",
       "  'added',\n",
       "  'bush',\n",
       "  'crowd',\n",
       "  'miss',\n",
       "  'economy',\n",
       "  'msnbc',\n",
       "  'running',\n",
       "  'administration',\n",
       "  'news',\n",
       "  'change',\n",
       "  'fire',\n",
       "  'speaking',\n",
       "  'birthdayparty',\n",
       "  'listening',\n",
       "  'choose',\n",
       "  'size',\n",
       "  'cut',\n",
       "  'watching',\n",
       "  'former_president',\n",
       "  'superspreader',\n",
       "  'funny',\n",
       "  'anthonyfauci'],\n",
       " ['voting',\n",
       "  'wise',\n",
       "  'cover',\n",
       "  'foreign',\n",
       "  'voteblue',\n",
       "  'bidenharris',\n",
       "  'party',\n",
       "  'ballot',\n",
       "  'friend',\n",
       "  'poll',\n",
       "  'voter',\n",
       "  'block',\n",
       "  'family',\n",
       "  'caravan',\n",
       "  'mail',\n",
       "  'registered',\n",
       "  'black',\n",
       "  'line',\n",
       "  'conservative',\n",
       "  'favorite',\n",
       "  'celebrity',\n",
       "  'artist',\n",
       "  'though',\n",
       "  'stop',\n",
       "  'cause',\n",
       "  'post',\n",
       "  'may',\n",
       "  'best',\n",
       "  'parent',\n",
       "  'govote'],\n",
       " ['year',\n",
       "  'old',\n",
       "  'office',\n",
       "  'past',\n",
       "  'job',\n",
       "  'michigan',\n",
       "  'history',\n",
       "  'growth',\n",
       "  'tax',\n",
       "  'two',\n",
       "  'debt',\n",
       "  'least',\n",
       "  'politics',\n",
       "  'yet',\n",
       "  'lying',\n",
       "  'almost',\n",
       "  'best',\n",
       "  'worst',\n",
       "  'unemployment',\n",
       "  'since',\n",
       "  'change',\n",
       "  'world',\n",
       "  'blue',\n",
       "  'modern',\n",
       "  'trillion',\n",
       "  'long',\n",
       "  'end',\n",
       "  'term',\n",
       "  'political',\n",
       "  'havent'],\n",
       " ['campaign',\n",
       "  'electionday',\n",
       "  'michigan',\n",
       "  'bidenharris',\n",
       "  'release',\n",
       "  'ballot',\n",
       "  'question',\n",
       "  'national',\n",
       "  'pretty',\n",
       "  'scale',\n",
       "  'currently',\n",
       "  'bus',\n",
       "  'hand',\n",
       "  'report',\n",
       "  'opportunity',\n",
       "  'call',\n",
       "  'event',\n",
       "  'attorneygeneral',\n",
       "  'signal',\n",
       "  'cinema',\n",
       "  'result',\n",
       "  'ahead',\n",
       "  'hour',\n",
       "  'song',\n",
       "  'nation',\n",
       "  'effort',\n",
       "  'outcome',\n",
       "  'issue',\n",
       "  'swing',\n",
       "  'license'],\n",
       " ['lady',\n",
       "  'job',\n",
       "  'legend',\n",
       "  'video',\n",
       "  'woman',\n",
       "  'brave',\n",
       "  'change',\n",
       "  'fame',\n",
       "  'famous',\n",
       "  'congratulation',\n",
       "  'artist',\n",
       "  'fan',\n",
       "  'government',\n",
       "  'music',\n",
       "  'story',\n",
       "  'favorite',\n",
       "  'singing',\n",
       "  'student',\n",
       "  'moment',\n",
       "  'cantar',\n",
       "  'twitter',\n",
       "  'enemy',\n",
       "  'swift',\n",
       "  'old',\n",
       "  'speaking',\n",
       "  'ban',\n",
       "  'female',\n",
       "  'minute',\n",
       "  'shot',\n",
       "  'shallow'],\n",
       " ['trumpsupporter',\n",
       "  'racist',\n",
       "  'blacklivesmatter',\n",
       "  'white',\n",
       "  'video',\n",
       "  'hate',\n",
       "  'police',\n",
       "  'gun',\n",
       "  'block',\n",
       "  'black',\n",
       "  'stupid',\n",
       "  'riot',\n",
       "  'literally',\n",
       "  'feel',\n",
       "  'boarding',\n",
       "  'caravan',\n",
       "  'crazy',\n",
       "  'cop',\n",
       "  'friend',\n",
       "  'rioting',\n",
       "  'dumb',\n",
       "  'violent',\n",
       "  'suck',\n",
       "  'act',\n",
       "  'either',\n",
       "  'try',\n",
       "  'truck',\n",
       "  'getting',\n",
       "  'group',\n",
       "  'angry'],\n",
       " ['votejoebiden',\n",
       "  'change',\n",
       "  'woman',\n",
       "  'government',\n",
       "  'fame',\n",
       "  'famous',\n",
       "  'brave',\n",
       "  'congratulation',\n",
       "  'sending',\n",
       "  'heaven',\n",
       "  'born',\n",
       "  'looking',\n",
       "  'save',\n",
       "  'able',\n",
       "  'help',\n",
       "  'red',\n",
       "  'mailinballot',\n",
       "  'communicationsdirector',\n",
       "  'wi',\n",
       "  'reduce',\n",
       "  'drop',\n",
       "  'life',\n",
       "  'text',\n",
       "  'call',\n",
       "  'enough',\n",
       "  'friend',\n",
       "  'registered',\n",
       "  'yet',\n",
       "  'stupid',\n",
       "  'baby'],\n",
       " ['rally',\n",
       "  'hold',\n",
       "  'michigan',\n",
       "  'watching',\n",
       "  'trump',\n",
       "  'crowd',\n",
       "  'supporter',\n",
       "  'superspreader',\n",
       "  'victory',\n",
       "  'moment',\n",
       "  'host',\n",
       "  'deputy',\n",
       "  'political',\n",
       "  'bidensupporter',\n",
       "  'senior',\n",
       "  'trumprally',\n",
       "  'study',\n",
       "  'caught',\n",
       "  'cold',\n",
       "  'beating',\n",
       "  'death',\n",
       "  'tape',\n",
       "  'bidenharris',\n",
       "  'north',\n",
       "  'campaignrally',\n",
       "  'speaking',\n",
       "  'broadcast',\n",
       "  'embarrassed',\n",
       "  'photo',\n",
       "  'huge'],\n",
       " ['covid',\n",
       "  'death',\n",
       "  'war',\n",
       "  'world',\n",
       "  'coviddeaths',\n",
       "  'foreign',\n",
       "  'losing',\n",
       "  'badly',\n",
       "  'exceed',\n",
       "  'anthonyfauci',\n",
       "  'week',\n",
       "  'trumprally',\n",
       "  'case',\n",
       "  'mask',\n",
       "  'pandemic',\n",
       "  'response',\n",
       "  'die',\n",
       "  'virus',\n",
       "  'study',\n",
       "  'civil',\n",
       "  'fire',\n",
       "  'economy',\n",
       "  'dead',\n",
       "  'superspreader',\n",
       "  'due',\n",
       "  'plan',\n",
       "  'lockdown',\n",
       "  'control',\n",
       "  'infection',\n",
       "  'rate'],\n",
       " ['votedonaldtrump',\n",
       "  'friend',\n",
       "  'black',\n",
       "  'hillaryclinton',\n",
       "  'woman',\n",
       "  'stupid',\n",
       "  'breakdown',\n",
       "  'family',\n",
       "  'science',\n",
       "  'patriot',\n",
       "  'hate',\n",
       "  'coming',\n",
       "  'mask',\n",
       "  'lockdown',\n",
       "  'respect',\n",
       "  'white',\n",
       "  'racist',\n",
       "  'best',\n",
       "  'manufacturer',\n",
       "  'world',\n",
       "  'heart',\n",
       "  'guy',\n",
       "  'worthy',\n",
       "  'red',\n",
       "  'save',\n",
       "  'freedom',\n",
       "  'feel',\n",
       "  'cannot',\n",
       "  'wont',\n",
       "  'water'],\n",
       " ['trump',\n",
       "  'voter',\n",
       "  'china',\n",
       "  'plan',\n",
       "  'poll',\n",
       "  'lie',\n",
       "  'believe',\n",
       "  'family',\n",
       "  'care',\n",
       "  'black',\n",
       "  'tax',\n",
       "  'life',\n",
       "  'guy',\n",
       "  'doesnt',\n",
       "  'hate',\n",
       "  'fact',\n",
       "  'whitehouse',\n",
       "  'medium',\n",
       "  'racist',\n",
       "  'stop',\n",
       "  'job',\n",
       "  'money',\n",
       "  'point',\n",
       "  'bad',\n",
       "  'help',\n",
       "  'party',\n",
       "  'video',\n",
       "  'call',\n",
       "  'god',\n",
       "  'feel']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = v_tfidf.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-31:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "applicable-devon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:1091: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# write out the different topics to CSV files to find optimal number of topics\n",
    "\n",
    "import csv\n",
    "\n",
    "# with open(f\"topic_words_{}.csv\", \"w\", newline=\"\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(a)\n",
    "\n",
    "for i in range(2, 15):\n",
    "    nmf_model = NMF(n_components=i, init='nndsvda')\n",
    "    doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "    words = v_tfidf.get_feature_names()\n",
    "    t = nmf_model.components_.argsort(axis=1)[:,-1:-31:-1]\n",
    "    topic_words = [[words[e] for e in l] for l in t]\n",
    "    tw_csv = np.array(topic_words).T\n",
    "    \n",
    "    with open(f\"../etc/topic-words/topic_words_{i:02d}.csv\", \"w+\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['topic-' +  str(x) for x in range(1, i+1)])\n",
    "        writer.writerows(tw_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "looking-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-channel",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "separate-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model = LatentDirichletAllocation(n_components=5)\n",
    "# doc_topic = lda_model.fit_transform(doc_word_ti)\n",
    "# doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "criminal-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = cv.get_feature_names()\n",
    "# t = lda_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "# topic_words = [[words[e] for e in l] for l in t]\n",
    "# topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-kingston",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impressed-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "little-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sid_obj = SentimentIntensityAnalyzer()\n",
    "# sentiment = []\n",
    "# for text in data.tweet:\n",
    "#     sentiment.append(sid_obj.polarity_scores(text))\n",
    "    \n",
    "# pd.concat([data,pd.DataFrame(sentiment)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-seller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-louis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
