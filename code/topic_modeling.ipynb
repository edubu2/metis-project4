{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stop\n",
    "from stop_words import stop_words as custom_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = list(nltk_stop.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    object\n",
       "date          datetime64[ns]\n",
       "time                  object\n",
       "user_id               object\n",
       "username              object\n",
       "hashtags              object\n",
       "trump                   bool\n",
       "biden                   bool\n",
       "original              object\n",
       "tweet                 object\n",
       "num_tokens             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/n2tk_limited.pick\")\n",
    "data.shape\n",
    "data.dtypes.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "micro-dryer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363310, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-origin",
   "metadata": {},
   "source": [
    "## TF/IDF Vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premier-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = custom_stop + nltk_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conventional-official",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363310, 5767)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_tfidf = TfidfVectorizer(max_df=0.4, min_df=0.00015, stop_words=stop_words)\n",
    "doc_word_ti = v_tfidf.fit_transform(data.tweet)\n",
    "doc_word_ti.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reliance",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-continent",
   "metadata": {},
   "source": [
    "Using the code below, I was able to identify the proper number of topics to use with NMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pleased-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write out the different topics to CSV files to find optimal number of topics\n",
    "\n",
    "import csv\n",
    "\n",
    "# for i in range(15, 26):\n",
    "#     nmf_model = NMF(n_components=i, init='nndsvda', max_iter=400)\n",
    "#     doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "#     words = v_tfidf.get_feature_names()\n",
    "#     t = nmf_model.components_.argsort(axis=1)[:,-1:-31:-1]\n",
    "#     topic_words = [[words[e] for e in l] for l in t]\n",
    "#     tw_csv = np.array(topic_words).T\n",
    "    \n",
    "#     with open(f\"../etc/topic-words/topic_words_{i:02d}.csv\", \"w+\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['topic-' +  str(x) for x in range(1, i+1)])\n",
    "#         writer.writerows(tw_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-occasion",
   "metadata": {},
   "source": [
    "It turns out, the best result is 30. Each topic represents a logical & relevant concept, with enough separation to separate similar ones, but not too much separation to the point the topics blend together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instructional-cooking",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_topic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-115d396323b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     pickle.dump( doc_topic, f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_topic' is not defined"
     ]
    }
   ],
   "source": [
    "# nmf_model = NMF(n_components=30, init='nndsvda', max_iter=400)\n",
    "# doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "# print(f\"doc_topic shape: {doc_topic.shape}\")\n",
    "# print(f\"Number of iterations used: {nmf_model.n_iter_}\")\n",
    "# # with open(\"pickle/nmf_model.pick\", 'wb') as f:\n",
    "# #     pickle.dump( nmf_model, f)\n",
    "\n",
    "# with open(\"pickle/nmf_doc_topics30.pick\", 'wb') as f:\n",
    "#     pickle.dump( doc_topic, f)\n",
    "    \n",
    "pd.DataFrame(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/nmf_model.pick\", 'rb') as f:\n",
    "    nmf_model = pickle.load( f)\n",
    "\n",
    "with open(\"pickle/nmf_doc_topics.pick\", 'rb') as f:\n",
    "    doc_topic = pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = v_tfidf.get_feature_names()\n",
    "# t = nmf_model.components_.argsort(axis=1)[:,-1:-21:-1]\n",
    "# topic_words = [[words[e] for e in l] for l in t]\n",
    "\n",
    "# with open(\"pickle/topic_words30.pick\", 'wb') as f:\n",
    "#     pickle.dump( topic_words, f)\n",
    "\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(topic_words)\n",
    "tmp.to_csv(\"topic_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle/topic_words.pick\", 'rb') as f:\n",
    "    topic_words = pickle.load( f)\n",
    "\n",
    "topic_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
