{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stop\n",
    "from stop_words import stop_words as custom_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = list(nltk_stop.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    object\n",
       "date          datetime64[ns]\n",
       "time                  object\n",
       "user_id               object\n",
       "username              object\n",
       "hashtags              object\n",
       "trump                   bool\n",
       "biden                   bool\n",
       "original              object\n",
       "tweet                 object\n",
       "num_tokens             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/n2tk_limited.pick\")\n",
    "data.shape\n",
    "data.dtypes.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minimal-burton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363310, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset='tweet', inplace=True)\n",
    "data.to_pickle(\"pickle/n2tk_limited.pick\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-origin",
   "metadata": {},
   "source": [
    "## TF/IDF Vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premier-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = custom_stop + nltk_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conventional-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tfidf = TfidfVectorizer(max_df=0.4, min_df=0.00015, stop_words=stop_words)\n",
    "doc_word_ti = v_tfidf.fit_transform(data.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reliance",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-continent",
   "metadata": {},
   "source": [
    "Using the code below, I was able to identify the proper number of topics to use with NMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pleased-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write out the different topics to CSV files to find optimal number of topics\n",
    "\n",
    "import csv\n",
    "\n",
    "# for i in range(15, 26):\n",
    "#     nmf_model = NMF(n_components=i, init='nndsvda', max_iter=400)\n",
    "#     doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "#     words = v_tfidf.get_feature_names()\n",
    "#     t = nmf_model.components_.argsort(axis=1)[:,-1:-31:-1]\n",
    "#     topic_words = [[words[e] for e in l] for l in t]\n",
    "#     tw_csv = np.array(topic_words).T\n",
    "    \n",
    "#     with open(f\"../etc/topic-words/topic_words_{i:02d}.csv\", \"w+\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['topic-' +  str(x) for x in range(1, i+1)])\n",
    "#         writer.writerows(tw_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-occasion",
   "metadata": {},
   "source": [
    "It turns out, the best result is 13. Each topic represents a logical & relevant concept, with enough separation to separate similar ones, but not too much separation to the point the topics blend together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "instructional-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_topic shape: (363310, 13)\n",
      "Number of iterations used: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.047775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.049943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.038826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363305</th>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363306</th>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055385</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363307</th>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.006103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363308</th>\n",
       "      <td>0.011595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363309</th>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363310 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.000836  0.000300  0.000000  0.000892  0.000000  0.000066  0.000000   \n",
       "1       0.003752  0.001583  0.000750  0.000000  0.000577  0.000377  0.000000   \n",
       "2       0.001226  0.001190  0.000000  0.000064  0.047775  0.000000  0.000047   \n",
       "3       0.001565  0.001057  0.002666  0.049943  0.000000  0.003429  0.000857   \n",
       "4       0.000000  0.028202  0.000000  0.000000  0.000000  0.000222  0.000520   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "363305  0.004147  0.001326  0.000000  0.000000  0.002541  0.000889  0.000000   \n",
       "363306  0.002246  0.000000  0.000000  0.000141  0.000198  0.000482  0.000055   \n",
       "363307  0.002394  0.000766  0.007797  0.001437  0.000000  0.002167  0.001311   \n",
       "363308  0.011595  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "363309  0.004017  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              7         8         9         10        11        12  \n",
       "0       0.000729  0.000038  0.003112  0.003755  0.000000  0.000308  \n",
       "1       0.006958  0.001502  0.000000  0.000000  0.000266  0.001017  \n",
       "2       0.006574  0.000035  0.000000  0.000134  0.000000  0.000000  \n",
       "3       0.000000  0.000000  0.004633  0.002868  0.000472  0.000000  \n",
       "4       0.000000  0.000000  0.000000  0.020264  0.038826  0.000000  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "363305  0.010283  0.001982  0.001314  0.005024  0.000000  0.002434  \n",
       "363306  0.000000  0.055385  0.029034  0.000036  0.000000  0.000688  \n",
       "363307  0.000000  0.000000  0.002420  0.001564  0.002703  0.006103  \n",
       "363308  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "363309  0.000000  0.039674  0.000000  0.003946  0.000166  0.000000  \n",
       "\n",
       "[363310 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=13, init='nndsvda')\n",
    "doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "print(f\"doc_topic shape: {doc_topic.shape}\")\n",
    "print(f\"Number of iterations used: {nmf_model.n_iter_}\")\n",
    "with open(\"pickle/nmf_model.pick\", 'wb') as f:\n",
    "    pickle.dump( nmf_model, f)\n",
    "\n",
    "with open(\"pickle/nmf_doc_topics.pick\", 'wb') as f:\n",
    "    pickle.dump( doc_topic, f)\n",
    "    \n",
    "pd.DataFrame(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "composed-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"pickle/nmf_model.pick\", 'rb') as f:\n",
    "#     nmf_model = pickle.load( f)\n",
    "\n",
    "# with open(\"pickle/nmf_doc_topics.pick\", 'rb') as f:\n",
    "#     doc_topic = pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surface-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hunterbiden',\n",
       "  'story',\n",
       "  'twitter',\n",
       "  'news',\n",
       "  'real',\n",
       "  'cnn',\n",
       "  'life',\n",
       "  'trumpsupporter',\n",
       "  'help',\n",
       "  'world',\n",
       "  'foxnews',\n",
       "  'fact',\n",
       "  'since',\n",
       "  'call',\n",
       "  'maybe',\n",
       "  'video',\n",
       "  'post',\n",
       "  'oh',\n",
       "  'question',\n",
       "  'getting'],\n",
       " ['vote',\n",
       "  'votejoebiden',\n",
       "  'ballot',\n",
       "  'votedonaldtrump',\n",
       "  'party',\n",
       "  'voter',\n",
       "  'candidate',\n",
       "  'change',\n",
       "  'poll',\n",
       "  'cast',\n",
       "  'electionday',\n",
       "  'democracy',\n",
       "  'enough',\n",
       "  'bidenharris',\n",
       "  'save',\n",
       "  'line',\n",
       "  'mail',\n",
       "  'life',\n",
       "  'help',\n",
       "  'voteblue'],\n",
       " ['covid',\n",
       "  'positive',\n",
       "  'test',\n",
       "  'death',\n",
       "  'whitehouse',\n",
       "  'pandemic',\n",
       "  'hospital',\n",
       "  'tested',\n",
       "  'virus',\n",
       "  'negative',\n",
       "  'response',\n",
       "  'plan',\n",
       "  'doctor',\n",
       "  'die',\n",
       "  'diagnosis',\n",
       "  'infected',\n",
       "  'dead',\n",
       "  'treatment',\n",
       "  'economy',\n",
       "  'getting'],\n",
       " ['kamalaharris',\n",
       "  'mikepence',\n",
       "  'votejoebiden',\n",
       "  'nancypelosi',\n",
       "  'ballot',\n",
       "  'plan',\n",
       "  'bidenharris',\n",
       "  'ticket',\n",
       "  'vicepresident',\n",
       "  'amendment',\n",
       "  'senator',\n",
       "  'woman',\n",
       "  'socialist',\n",
       "  'berniesanders',\n",
       "  'blue',\n",
       "  'whitehouse',\n",
       "  'sign',\n",
       "  'future',\n",
       "  'candidate',\n",
       "  'running'],\n",
       " ['debate',\n",
       "  'question',\n",
       "  'presidential',\n",
       "  'town',\n",
       "  'hall',\n",
       "  'answer',\n",
       "  'virtual',\n",
       "  'moderator',\n",
       "  'commission',\n",
       "  'second',\n",
       "  'mikepence',\n",
       "  'rule',\n",
       "  'nbc',\n",
       "  'test',\n",
       "  'candidate',\n",
       "  'abc',\n",
       "  'tested',\n",
       "  'positive',\n",
       "  'stage',\n",
       "  'watching'],\n",
       " ['trump',\n",
       "  'rally',\n",
       "  'plan',\n",
       "  'fault',\n",
       "  'whitehouse',\n",
       "  'policy',\n",
       "  'tweet',\n",
       "  'response',\n",
       "  'base',\n",
       "  'doctor',\n",
       "  'word',\n",
       "  'supporter',\n",
       "  'action',\n",
       "  'behavior',\n",
       "  'pandemic',\n",
       "  'failure',\n",
       "  'presidency',\n",
       "  'health',\n",
       "  'attack',\n",
       "  'child'],\n",
       " ['barackobama',\n",
       "  'hillaryclinton',\n",
       "  'administration',\n",
       "  'economy',\n",
       "  'bush',\n",
       "  'pandemic',\n",
       "  'speech',\n",
       "  'cage',\n",
       "  'policy',\n",
       "  'war',\n",
       "  'presidency',\n",
       "  'took',\n",
       "  'built',\n",
       "  'former_president',\n",
       "  'berniesanders',\n",
       "  'lost',\n",
       "  'crime',\n",
       "  'corrupt',\n",
       "  'unemployment',\n",
       "  'term'],\n",
       " ['voting',\n",
       "  'voter',\n",
       "  'poll',\n",
       "  'party',\n",
       "  'ballot',\n",
       "  'candidate',\n",
       "  'bidenharris',\n",
       "  'mail',\n",
       "  'number',\n",
       "  'lead',\n",
       "  'fraud',\n",
       "  'line',\n",
       "  'either',\n",
       "  'friend',\n",
       "  'suppression',\n",
       "  'registered',\n",
       "  'votedonaldtrump',\n",
       "  'electionday',\n",
       "  'blue',\n",
       "  'polling'],\n",
       " ['campaign',\n",
       "  'negative',\n",
       "  'rally',\n",
       "  'event',\n",
       "  'voter',\n",
       "  'bus',\n",
       "  'running',\n",
       "  'money',\n",
       "  'bidenharris',\n",
       "  'manager',\n",
       "  'presidential',\n",
       "  'official',\n",
       "  'suspend',\n",
       "  'supporter',\n",
       "  'test',\n",
       "  'attack',\n",
       "  'pull',\n",
       "  'candidate',\n",
       "  'smear',\n",
       "  'report'],\n",
       " ['tax',\n",
       "  'china',\n",
       "  'money',\n",
       "  'pay',\n",
       "  'business',\n",
       "  'cut',\n",
       "  'russia',\n",
       "  'bank',\n",
       "  'return',\n",
       "  'deal',\n",
       "  'dollar',\n",
       "  'paying',\n",
       "  'rich',\n",
       "  'plan',\n",
       "  'government',\n",
       "  'secret',\n",
       "  'income',\n",
       "  'making',\n",
       "  'class',\n",
       "  'economy'],\n",
       " ['black',\n",
       "  'racist',\n",
       "  'woman',\n",
       "  'white',\n",
       "  'community',\n",
       "  'bill',\n",
       "  'crime',\n",
       "  'whitesupremacy',\n",
       "  'racism',\n",
       "  'hate',\n",
       "  'voter',\n",
       "  'blacklivesmatter',\n",
       "  'group',\n",
       "  'cube',\n",
       "  'aint',\n",
       "  'trumpsupporter',\n",
       "  'folk',\n",
       "  'plan',\n",
       "  'minority',\n",
       "  'supporting'],\n",
       " ['lie',\n",
       "  'believe',\n",
       "  'truth',\n",
       "  'fact',\n",
       "  'lying',\n",
       "  'liar',\n",
       "  'word',\n",
       "  'true',\n",
       "  'lied',\n",
       "  'virus',\n",
       "  'mouth',\n",
       "  'stupid',\n",
       "  'hate',\n",
       "  'spread',\n",
       "  'spreading',\n",
       "  'claim',\n",
       "  'check',\n",
       "  'cheat',\n",
       "  'propaganda',\n",
       "  'cannot'],\n",
       " ['mask',\n",
       "  'wear',\n",
       "  'wearing',\n",
       "  'virus',\n",
       "  'rally',\n",
       "  'mandate',\n",
       "  'whitehouse',\n",
       "  'socialdistancing',\n",
       "  'without',\n",
       "  'life',\n",
       "  'distance',\n",
       "  'spread',\n",
       "  'superspreader',\n",
       "  'event',\n",
       "  'science',\n",
       "  'fun',\n",
       "  'sick',\n",
       "  'infected',\n",
       "  'hand',\n",
       "  'protect']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = v_tfidf.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-21:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "\n",
    "with open(\"pickle/topic_words.pick\", 'wb') as f:\n",
    "    pickle.dump( topic_words, f)\n",
    "\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "engaging-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(topic_words)\n",
    "tmp.to_csv(\"topic_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "inner-contemporary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hunterbiden',\n",
       "  'story',\n",
       "  'twitter',\n",
       "  'news',\n",
       "  'real',\n",
       "  'cnn',\n",
       "  'life',\n",
       "  'trumpsupporter',\n",
       "  'help',\n",
       "  'world',\n",
       "  'foxnews',\n",
       "  'fact',\n",
       "  'since',\n",
       "  'call',\n",
       "  'maybe',\n",
       "  'video',\n",
       "  'post',\n",
       "  'oh',\n",
       "  'question',\n",
       "  'getting'],\n",
       " ['vote',\n",
       "  'votejoebiden',\n",
       "  'ballot',\n",
       "  'votedonaldtrump',\n",
       "  'party',\n",
       "  'voter',\n",
       "  'candidate',\n",
       "  'change',\n",
       "  'poll',\n",
       "  'cast',\n",
       "  'electionday',\n",
       "  'democracy',\n",
       "  'enough',\n",
       "  'bidenharris',\n",
       "  'save',\n",
       "  'line',\n",
       "  'mail',\n",
       "  'life',\n",
       "  'help',\n",
       "  'voteblue'],\n",
       " ['covid',\n",
       "  'positive',\n",
       "  'test',\n",
       "  'death',\n",
       "  'whitehouse',\n",
       "  'pandemic',\n",
       "  'hospital',\n",
       "  'tested',\n",
       "  'virus',\n",
       "  'negative',\n",
       "  'response',\n",
       "  'plan',\n",
       "  'doctor',\n",
       "  'die',\n",
       "  'diagnosis',\n",
       "  'infected',\n",
       "  'dead',\n",
       "  'treatment',\n",
       "  'economy',\n",
       "  'getting'],\n",
       " ['kamalaharris',\n",
       "  'mikepence',\n",
       "  'votejoebiden',\n",
       "  'nancypelosi',\n",
       "  'ballot',\n",
       "  'plan',\n",
       "  'bidenharris',\n",
       "  'ticket',\n",
       "  'vicepresident',\n",
       "  'amendment',\n",
       "  'senator',\n",
       "  'woman',\n",
       "  'socialist',\n",
       "  'berniesanders',\n",
       "  'blue',\n",
       "  'whitehouse',\n",
       "  'sign',\n",
       "  'future',\n",
       "  'candidate',\n",
       "  'running'],\n",
       " ['debate',\n",
       "  'question',\n",
       "  'presidential',\n",
       "  'town',\n",
       "  'hall',\n",
       "  'answer',\n",
       "  'virtual',\n",
       "  'moderator',\n",
       "  'commission',\n",
       "  'second',\n",
       "  'mikepence',\n",
       "  'rule',\n",
       "  'nbc',\n",
       "  'test',\n",
       "  'candidate',\n",
       "  'abc',\n",
       "  'tested',\n",
       "  'positive',\n",
       "  'stage',\n",
       "  'watching'],\n",
       " ['trump',\n",
       "  'rally',\n",
       "  'plan',\n",
       "  'fault',\n",
       "  'whitehouse',\n",
       "  'policy',\n",
       "  'tweet',\n",
       "  'response',\n",
       "  'base',\n",
       "  'doctor',\n",
       "  'word',\n",
       "  'supporter',\n",
       "  'action',\n",
       "  'behavior',\n",
       "  'pandemic',\n",
       "  'failure',\n",
       "  'presidency',\n",
       "  'health',\n",
       "  'attack',\n",
       "  'child'],\n",
       " ['barackobama',\n",
       "  'hillaryclinton',\n",
       "  'administration',\n",
       "  'economy',\n",
       "  'bush',\n",
       "  'pandemic',\n",
       "  'speech',\n",
       "  'cage',\n",
       "  'policy',\n",
       "  'war',\n",
       "  'presidency',\n",
       "  'took',\n",
       "  'built',\n",
       "  'former_president',\n",
       "  'berniesanders',\n",
       "  'lost',\n",
       "  'crime',\n",
       "  'corrupt',\n",
       "  'unemployment',\n",
       "  'term'],\n",
       " ['voting',\n",
       "  'voter',\n",
       "  'poll',\n",
       "  'party',\n",
       "  'ballot',\n",
       "  'candidate',\n",
       "  'bidenharris',\n",
       "  'mail',\n",
       "  'number',\n",
       "  'lead',\n",
       "  'fraud',\n",
       "  'line',\n",
       "  'either',\n",
       "  'friend',\n",
       "  'suppression',\n",
       "  'registered',\n",
       "  'votedonaldtrump',\n",
       "  'electionday',\n",
       "  'blue',\n",
       "  'polling'],\n",
       " ['campaign',\n",
       "  'negative',\n",
       "  'rally',\n",
       "  'event',\n",
       "  'voter',\n",
       "  'bus',\n",
       "  'running',\n",
       "  'money',\n",
       "  'bidenharris',\n",
       "  'manager',\n",
       "  'presidential',\n",
       "  'official',\n",
       "  'suspend',\n",
       "  'supporter',\n",
       "  'test',\n",
       "  'attack',\n",
       "  'pull',\n",
       "  'candidate',\n",
       "  'smear',\n",
       "  'report'],\n",
       " ['tax',\n",
       "  'china',\n",
       "  'money',\n",
       "  'pay',\n",
       "  'business',\n",
       "  'cut',\n",
       "  'russia',\n",
       "  'bank',\n",
       "  'return',\n",
       "  'deal',\n",
       "  'dollar',\n",
       "  'paying',\n",
       "  'rich',\n",
       "  'plan',\n",
       "  'government',\n",
       "  'secret',\n",
       "  'income',\n",
       "  'making',\n",
       "  'class',\n",
       "  'economy'],\n",
       " ['black',\n",
       "  'racist',\n",
       "  'woman',\n",
       "  'white',\n",
       "  'community',\n",
       "  'bill',\n",
       "  'crime',\n",
       "  'whitesupremacy',\n",
       "  'racism',\n",
       "  'hate',\n",
       "  'voter',\n",
       "  'blacklivesmatter',\n",
       "  'group',\n",
       "  'cube',\n",
       "  'aint',\n",
       "  'trumpsupporter',\n",
       "  'folk',\n",
       "  'plan',\n",
       "  'minority',\n",
       "  'supporting'],\n",
       " ['lie',\n",
       "  'believe',\n",
       "  'truth',\n",
       "  'fact',\n",
       "  'lying',\n",
       "  'liar',\n",
       "  'word',\n",
       "  'true',\n",
       "  'lied',\n",
       "  'virus',\n",
       "  'mouth',\n",
       "  'stupid',\n",
       "  'hate',\n",
       "  'spread',\n",
       "  'spreading',\n",
       "  'claim',\n",
       "  'check',\n",
       "  'cheat',\n",
       "  'propaganda',\n",
       "  'cannot'],\n",
       " ['mask',\n",
       "  'wear',\n",
       "  'wearing',\n",
       "  'virus',\n",
       "  'rally',\n",
       "  'mandate',\n",
       "  'whitehouse',\n",
       "  'socialdistancing',\n",
       "  'without',\n",
       "  'life',\n",
       "  'distance',\n",
       "  'spread',\n",
       "  'superspreader',\n",
       "  'event',\n",
       "  'science',\n",
       "  'fun',\n",
       "  'sick',\n",
       "  'infected',\n",
       "  'hand',\n",
       "  'protect']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"pickle/topic_words.pick\", 'rb') as f:\n",
    "    topic_words = pickle.load( f)\n",
    "\n",
    "topic_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
