{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stop\n",
    "from stop_words import stop_words as custom_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stop = list(nltk_stop.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"pickle/n2_tokenized_eff.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daily-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "      <th>tweet</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1323414108092420097</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:58:05</td>\n",
       "      <td>116649183</td>\n",
       "      <td>oriyod</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@roguesnradvisor I’ve done all I can.  Let me live in the Hope for today.  I voted  for the next President : Joe Biden.               the subconsciously cynical will use my mind as it’s personal playground tomorrow.</td>\n",
       "      <td>subconsciously cynical use mind personal playground</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81956</th>\n",
       "      <td>1323400816485634048</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:05:16</td>\n",
       "      <td>1237790695622148096</td>\n",
       "      <td>listenhere12</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>@realDonaldTrump This has to be the most egregious lies that Trump has ever told ... get out your dictionaries.   REPORT</td>\n",
       "      <td>egregious lie told dictionary report</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106741</th>\n",
       "      <td>1323382621976453120</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:52:58</td>\n",
       "      <td>11575102</td>\n",
       "      <td>tifotter</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@CivMilAir @atrupar Joe Biden will adjust your thermostat, reset all your passwords, leave your car dome light on, leave dishes in the sink, rake leaves and then just leave them. In a pile!</td>\n",
       "      <td>adjust thermostat reset password leave car dome light leave dish sink rake leaf leave pile</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "1613    1323414108092420097 2020-11-02  23:58:05            116649183   \n",
       "81956   1323400816485634048 2020-11-02  23:05:16  1237790695622148096   \n",
       "106741  1323382621976453120 2020-11-02  21:52:58             11575102   \n",
       "\n",
       "            username hashtags  trump  biden  \\\n",
       "1613          oriyod       []  False   True   \n",
       "81956   listenhere12       []   True  False   \n",
       "106741      tifotter       []  False   True   \n",
       "\n",
       "                                                                                                                                                                                                                       original  \\\n",
       "1613    @roguesnradvisor I’ve done all I can.  Let me live in the Hope for today.  I voted  for the next President : Joe Biden.               the subconsciously cynical will use my mind as it’s personal playground tomorrow.   \n",
       "81956                                                                                                  @realDonaldTrump This has to be the most egregious lies that Trump has ever told ... get out your dictionaries.   REPORT   \n",
       "106741                            @CivMilAir @atrupar Joe Biden will adjust your thermostat, reset all your passwords, leave your car dome light on, leave dishes in the sink, rake leaves and then just leave them. In a pile!   \n",
       "\n",
       "                                                                                             tweet  \\\n",
       "1613                                           subconsciously cynical use mind personal playground   \n",
       "81956                                                         egregious lie told dictionary report   \n",
       "106741  adjust thermostat reset password leave car dome light leave dish sink rake leaf leave pile   \n",
       "\n",
       "        num_tokens  \n",
       "1613             6  \n",
       "81956            5  \n",
       "106741          15  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-origin",
   "metadata": {},
   "source": [
    "## TF/IDF Vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premier-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = custom_stop + nltk_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conventional-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tfidf = TfidfVectorizer(max_df=0.16, min_df=0.0002, stop_words=stop_words)\n",
    "doc_word_ti = v_tfidf.fit_transform(data.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reliance",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-continent",
   "metadata": {},
   "source": [
    "Using the code below, I was able to identify the proper number of topics to use with NMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pleased-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the different topics to CSV files to find optimal number of topics\n",
    "\n",
    "import csv\n",
    "\n",
    "# with open(f\"topic_words_{}.csv\", \"w\", newline=\"\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(a)\n",
    "\n",
    "# for i in range(2, 18):\n",
    "#     nmf_model = NMF(n_components=i, init='nndsvda', max_iter=400)\n",
    "#     doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "#     words = v_tfidf.get_feature_names()\n",
    "#     t = nmf_model.components_.argsort(axis=1)[:,-1:-31:-1]\n",
    "#     topic_words = [[words[e] for e in l] for l in t]\n",
    "#     tw_csv = np.array(topic_words).T\n",
    "    \n",
    "#     with open(f\"../etc/topic-words/topic_words_{i:02d}.csv\", \"w+\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['topic-' +  str(x) for x in range(1, i+1)])\n",
    "#         writer.writerows(tw_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-occasion",
   "metadata": {},
   "source": [
    "It turns out, the best result is 15. Each topic represents a logical & relevant concept, with enough separation to separate similar ones, but not too much separation to the point the topics blend together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instructional-cooking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (96000, 15)\n",
      "Number of iterations used: 32\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=15, init='nndsvda')\n",
    "doc_topic = nmf_model.fit_transform(doc_word_ti)\n",
    "print(f\"Shape: {doc_topic.shape}\")\n",
    "print(f\"Number of iterations used: {nmf_model.n_iter_}\")\n",
    "\n",
    "# pd.DataFrame(doc_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surface-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['vote',\n",
       "  'electoral',\n",
       "  'party',\n",
       "  'ballot',\n",
       "  'cast',\n",
       "  'democracy',\n",
       "  'attorneygeneral'],\n",
       " ['barackobama',\n",
       "  'cnn',\n",
       "  'steal',\n",
       "  'speech',\n",
       "  'hillaryclinton',\n",
       "  'pointer',\n",
       "  'hammer'],\n",
       " ['voting', 'wise', 'cover', 'foreign', 'voteblue', 'bidenharris', 'party'],\n",
       " ['year', 'job', 'tax', 'michigan', 'history', 'growth', 'two'],\n",
       " ['voter', 'poll', 'black', 'believe', 'care', 'life', 'guy'],\n",
       " ['lady', 'job', 'legend', 'video', 'woman', 'brave', 'change'],\n",
       " ['trumpsupporter',\n",
       "  'racist',\n",
       "  'blacklivesmatter',\n",
       "  'white',\n",
       "  'block',\n",
       "  'riot',\n",
       "  'police'],\n",
       " ['votejoebiden', 'change', 'woman', 'government', 'fame', 'famous', 'brave'],\n",
       " ['rally',\n",
       "  'hold',\n",
       "  'michigan',\n",
       "  'watching',\n",
       "  'crowd',\n",
       "  'supporter',\n",
       "  'superspreader'],\n",
       " ['covid', 'death', 'war', 'world', 'coviddeaths', 'foreign', 'losing'],\n",
       " ['votedonaldtrump',\n",
       "  'friend',\n",
       "  'black',\n",
       "  'family',\n",
       "  'hillaryclinton',\n",
       "  'breakdown',\n",
       "  'stupid'],\n",
       " ['trump', 'plan', 'lie', 'tax', 'coup', 'television', 'whitehouse'],\n",
       " ['china', 'evidence', 'breaking', 'payment', 'swindling', 'family', 'money'],\n",
       " ['electionday',\n",
       "  'pretty',\n",
       "  'question',\n",
       "  'national',\n",
       "  'currently',\n",
       "  'scale',\n",
       "  'call'],\n",
       " ['campaign',\n",
       "  'michigan',\n",
       "  'release',\n",
       "  'bidenharris',\n",
       "  'bus',\n",
       "  'ballot',\n",
       "  'opportunity']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = v_tfidf.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-8:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-evanescence",
   "metadata": {},
   "source": [
    "## Topics (NMF `n_components=15`)\n",
    "\n",
    "**pro-vote** \n",
    "\\['vote',\n",
    "  'electoral',\n",
    "  'party',\n",
    "  'ballot',\n",
    "  'cast',\n",
    "  'democracy',\n",
    "  'attorneygeneral'\\],\n",
    "  \n",
    "**past-presidencies**\n",
    " \\['barackobama',\n",
    "  'cnn',\n",
    "  'steal',\n",
    "  'speech',\n",
    "  'hillaryclinton',\n",
    "  'pointer',\n",
    "  'hammer'\\],\n",
    "  \n",
    "  **vote-blue**\n",
    " \\['voting', 'wise', 'cover', 'foreign', 'voteblue', 'bidenharris', 'party'\\],\n",
    " \n",
    " **economy**\n",
    " \\['year', 'job', 'tax', 'michigan', 'history', 'growth', 'two'\\],\n",
    " \n",
    " **racism**\n",
    " \\['voter', 'poll', 'black', 'believe', 'care', 'life', 'guy'\\],\n",
    " \n",
    " **female-vp**\n",
    " \\['lady', 'job', 'legend', 'video', 'woman', 'brave', 'change'\\],\n",
    " \n",
    " **anti-trump-supporter**\n",
    " \\['trumpsupporter',\n",
    "  'racist',\n",
    "  'blacklivesmatter',\n",
    "  'white',\n",
    "  'block',\n",
    "  'riot',\n",
    "  'police'\\],\n",
    "  \n",
    "**pro-biden**\n",
    " \\['votejoebiden', 'change', 'woman', 'government', 'fame', 'famous', 'brave'\\],\n",
    " \n",
    "**trump-rallies-during-covid**\n",
    " \\['rally',\n",
    "  'hold',\n",
    "  'michigan',\n",
    "  'watching',\n",
    "  'crowd',\n",
    "  'supporter',\n",
    "  'superspreader'\\],\n",
    "  \n",
    " **covid-19**\n",
    " \\['covid', 'death', 'war', 'world', 'coviddeaths', 'foreign', 'losing'\\],\n",
    " \n",
    "**pro-trump**\n",
    " \\['votedonaldtrump',\n",
    "  'friend',\n",
    "  'black',\n",
    "  'family',\n",
    "  'hillaryclinton',\n",
    "  'breakdown',\n",
    "  'stupid'\\],\n",
    "  \n",
    "**trump-lies**\n",
    " \\['trump', 'plan', 'lie', 'tax', 'coup', 'television', 'whitehouse'\\],\n",
    " \n",
    "**foreign-affairs**\n",
    " \\['china', 'evidence', 'breaking', 'payment', 'swindling', 'family', 'money'\\],\n",
    " \n",
    "**voter-supression**\n",
    " \\['electionday',\n",
    "  'pretty',\n",
    "  'question',\n",
    "  'national',\n",
    "  'currently',\n",
    "  'scale',\n",
    "  'call'\\],\n",
    "  \n",
    "**campaign-info**\n",
    " \\['campaign',\n",
    "  'michigan',\n",
    "  'release',\n",
    "  'bidenharris',\n",
    "  'bus',\n",
    "  'ballot',\n",
    "  'opportunity'\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "looking-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-seller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-louis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
