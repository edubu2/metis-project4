{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-holiday",
   "metadata": {},
   "source": [
    "**Kelsey 1-1**\n",
    "\n",
    "- cleaning\n",
    "    - preprocessing until comfortable with words\n",
    "   \n",
    "- sentiment analysis on all tweets\n",
    "    - don't need to do any splitting at this stage\n",
    "    - TextBlob & VaderSentiment first, spacy if the results aren't as expected\n",
    "    \n",
    "- topic modeling\n",
    "    - decide: use all tweets (all topics) at once\n",
    "        - start here\n",
    "        - then can use these as features in the dataFrame and do splitting here\n",
    "    - or: split to trump/biden - then bot/not bot for each\n",
    "    - point here is there are multiple ways to split it\n",
    "        - no right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879311, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"pickle/df_t_raw.pick\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>1322684318125350914</td>\n",
       "      <td>1322683862175109120</td>\n",
       "      <td>2020-10-31 23:38:10 UTC</td>\n",
       "      <td>2020-10-31</td>\n",
       "      <td>23:38:10</td>\n",
       "      <td>0</td>\n",
       "      <td>941439774</td>\n",
       "      <td>centrist_phone</td>\n",
       "      <td>Dr Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@NateSilver538 Something odd happening in this...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/centrist_phone/status/1322...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'NateSilver538', 'name': 'Nat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9449</th>\n",
       "      <td>1314711646837694464</td>\n",
       "      <td>1314706514670612480</td>\n",
       "      <td>2020-10-09 23:37:37 UTC</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>23:37:37</td>\n",
       "      <td>0</td>\n",
       "      <td>1137629164326887426</td>\n",
       "      <td>acetoyourhead</td>\n",
       "      <td>Acetoyourhead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SteveSisolak @JoeBiden @KamalaHarris @JoeForN...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'screen_name': 'govsisolak', 'name': 'govern...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://pbs.twimg.com/tweet_video_thumb/Ej7L...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/acetoyourhead/status/13147...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>https://pbs.twimg.com/tweet_video_thumb/Ej7LRX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'SteveSisolak', 'name': 'Stev...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>1318339055642443776</td>\n",
       "      <td>1318339055642443776</td>\n",
       "      <td>2020-10-19 23:51:39 UTC</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>23:51:39</td>\n",
       "      <td>0</td>\n",
       "      <td>1179130056112824322</td>\n",
       "      <td>newguardsrising</td>\n",
       "      <td>Greg Wilson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ashlie_weeks as a former political appointee ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['dumptrump2020']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/NewGuardsRising/status/131...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/ashlie_weeks/status/131833...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id               created_at  \\\n",
       "10370  1322684318125350914  1322683862175109120  2020-10-31 23:38:10 UTC   \n",
       "9449   1314711646837694464  1314706514670612480  2020-10-09 23:37:37 UTC   \n",
       "3918   1318339055642443776  1318339055642443776  2020-10-19 23:51:39 UTC   \n",
       "\n",
       "             date      time  timezone              user_id         username  \\\n",
       "10370  2020-10-31  23:38:10         0            941439774   centrist_phone   \n",
       "9449   2020-10-09  23:37:37         0  1137629164326887426    acetoyourhead   \n",
       "3918   2020-10-19  23:51:39         0  1179130056112824322  newguardsrising   \n",
       "\n",
       "                name place                                              tweet  \\\n",
       "10370    Dr Moderate   NaN  @NateSilver538 Something odd happening in this...   \n",
       "9449   Acetoyourhead   NaN  @SteveSisolak @JoeBiden @KamalaHarris @JoeForN...   \n",
       "3918     Greg Wilson   NaN  @ashlie_weeks as a former political appointee ...   \n",
       "\n",
       "      language                                           mentions urls  \\\n",
       "10370       en                                                 []   []   \n",
       "9449        en  [{'screen_name': 'govsisolak', 'name': 'govern...   []   \n",
       "3918        en                                                 []   []   \n",
       "\n",
       "                                                  photos  replies_count  \\\n",
       "10370                                                 []              2   \n",
       "9449   ['https://pbs.twimg.com/tweet_video_thumb/Ej7L...              5   \n",
       "3918                                                  []              0   \n",
       "\n",
       "       retweets_count  likes_count           hashtags cashtags  \\\n",
       "10370               1           12                 []       []   \n",
       "9449                0           15                 []       []   \n",
       "3918                0            0  ['dumptrump2020']       []   \n",
       "\n",
       "                                                    link  retweet  \\\n",
       "10370  https://twitter.com/centrist_phone/status/1322...    False   \n",
       "9449   https://twitter.com/acetoyourhead/status/13147...    False   \n",
       "3918   https://twitter.com/NewGuardsRising/status/131...    False   \n",
       "\n",
       "                                               quote_url  video  \\\n",
       "10370                                                NaN      0   \n",
       "9449                                                 NaN      1   \n",
       "3918   https://twitter.com/ashlie_weeks/status/131833...      0   \n",
       "\n",
       "                                               thumbnail  near  geo  source  \\\n",
       "10370                                                NaN   NaN  NaN     NaN   \n",
       "9449   https://pbs.twimg.com/tweet_video_thumb/Ej7LRX...   NaN  NaN     NaN   \n",
       "3918                                                 NaN   NaN  NaN     NaN   \n",
       "\n",
       "       user_rt_id  user_rt  retweet_id  \\\n",
       "10370         NaN      NaN         NaN   \n",
       "9449          NaN      NaN         NaN   \n",
       "3918          NaN      NaN         NaN   \n",
       "\n",
       "                                                reply_to  retweet_date  \\\n",
       "10370  [{'screen_name': 'NateSilver538', 'name': 'Nat...           NaN   \n",
       "9449   [{'screen_name': 'SteveSisolak', 'name': 'Stev...           NaN   \n",
       "3918                                                  []           NaN   \n",
       "\n",
       "       translate  trans_src  trans_dest  biden  trump  \n",
       "10370        NaN        NaN         NaN      1      0  \n",
       "9449         NaN        NaN         NaN      1      0  \n",
       "3918         NaN        NaN         NaN      1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-muscle",
   "metadata": {},
   "source": [
    "Now let's create a subset, containing the same amount of Trump tweets as Biden tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aging-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.trump == 0) & (df.biden == 1)\n",
    "biden_tweets = df[mask]\n",
    "\n",
    "mask = (df.trump == 1) & (df.biden == 0)\n",
    "trump_tweets = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recreational-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14987</th>\n",
       "      <td>1312529747100930050</td>\n",
       "      <td>1312230127112204289</td>\n",
       "      <td>2020-10-03 23:07:31 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:07:31</td>\n",
       "      <td>0</td>\n",
       "      <td>2600787139</td>\n",
       "      <td>brh_pino</td>\n",
       "      <td>Orange is the New Stupid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jrgaillot @JoeBiden No.</td>\n",
       "      <td>und</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/BRH_Pino/status/1312529747...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'jrgaillot', 'name': 'JR Gail...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15031</th>\n",
       "      <td>1319783792391892992</td>\n",
       "      <td>1319783792391892992</td>\n",
       "      <td>2020-10-23 23:32:31 UTC</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>23:32:31</td>\n",
       "      <td>0</td>\n",
       "      <td>1011057087386914817</td>\n",
       "      <td>cd_smithy</td>\n",
       "      <td>CdSmithy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Obviously Mr. Jenkins has need of more educati...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'screen_name': 'wsj', 'name': 'the wall stre...</td>\n",
       "      <td>['https://apple.news/AMoFESa8NQci-vLmRnRj_jQ']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/cd_smithy/status/131978379...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>1312529761139187712</td>\n",
       "      <td>1312518819370291202</td>\n",
       "      <td>2020-10-03 23:07:35 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:07:35</td>\n",
       "      <td>0</td>\n",
       "      <td>801253065684881408</td>\n",
       "      <td>seeseerider2</td>\n",
       "      <td>vps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BreitbartNews Just watched the Bork confirmat...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/Seeseerider2/status/131252...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'BreitbartNews', 'name': 'Bre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id               created_at  \\\n",
       "14987  1312529747100930050  1312230127112204289  2020-10-03 23:07:31 UTC   \n",
       "15031  1319783792391892992  1319783792391892992  2020-10-23 23:32:31 UTC   \n",
       "14968  1312529761139187712  1312518819370291202  2020-10-03 23:07:35 UTC   \n",
       "\n",
       "             date      time timezone              user_id      username  \\\n",
       "14987  2020-10-03  23:07:31        0           2600787139      brh_pino   \n",
       "15031  2020-10-23  23:32:31        0  1011057087386914817     cd_smithy   \n",
       "14968  2020-10-03  23:07:35        0   801253065684881408  seeseerider2   \n",
       "\n",
       "                           name place  \\\n",
       "14987  Orange is the New Stupid   NaN   \n",
       "15031                  CdSmithy   NaN   \n",
       "14968                       vps   NaN   \n",
       "\n",
       "                                                   tweet language  \\\n",
       "14987                           @jrgaillot @JoeBiden No.      und   \n",
       "15031  Obviously Mr. Jenkins has need of more educati...       en   \n",
       "14968  @BreitbartNews Just watched the Bork confirmat...       en   \n",
       "\n",
       "                                                mentions  \\\n",
       "14987                                                 []   \n",
       "15031  [{'screen_name': 'wsj', 'name': 'the wall stre...   \n",
       "14968                                                 []   \n",
       "\n",
       "                                                 urls photos replies_count  \\\n",
       "14987                                              []     []             0   \n",
       "15031  ['https://apple.news/AMoFESa8NQci-vLmRnRj_jQ']     []             0   \n",
       "14968                                              []     []             0   \n",
       "\n",
       "      retweets_count likes_count hashtags cashtags  \\\n",
       "14987              0           0       []       []   \n",
       "15031              0           0       []       []   \n",
       "14968              0           0       []       []   \n",
       "\n",
       "                                                    link retweet quote_url  \\\n",
       "14987  https://twitter.com/BRH_Pino/status/1312529747...   False       NaN   \n",
       "15031  https://twitter.com/cd_smithy/status/131978379...   False       NaN   \n",
       "14968  https://twitter.com/Seeseerider2/status/131252...   False       NaN   \n",
       "\n",
       "      video thumbnail near  geo source user_rt_id user_rt retweet_id  \\\n",
       "14987     0       NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "15031     0       NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "14968     0       NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                                reply_to retweet_date  \\\n",
       "14987  [{'screen_name': 'jrgaillot', 'name': 'JR Gail...          NaN   \n",
       "15031                                                 []          NaN   \n",
       "14968  [{'screen_name': 'BreitbartNews', 'name': 'Bre...          NaN   \n",
       "\n",
       "      translate trans_src trans_dest biden trump  \n",
       "14987       NaN       NaN        NaN     1     0  \n",
       "15031       NaN       NaN        NaN     0     1  \n",
       "14968       NaN       NaN        NaN     1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = pd.DataFrame(columns=df.columns)\n",
    "subset = subset.append(biden_tweets.tail(50))\n",
    "subset = subset.append(trump_tweets.tail(50))\n",
    "\n",
    "subset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>@CMWooly @JoeBiden @jimdicker He called for th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@CMWooly @JoeBiden @jimdicker He called for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14946</th>\n",
       "      <td>@MissyPDX @HKrassenstein @JoeBiden Got a probl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@MissyPDX @HKrassenstein @JoeBiden Got a probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>@CarolyneMas @BCStevens77 @JoeBiden Not only w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@CarolyneMas @BCStevens77 @JoeBiden Not only w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet trump biden  \\\n",
       "14945  @CMWooly @JoeBiden @jimdicker He called for th...     0     1   \n",
       "14946  @MissyPDX @HKrassenstein @JoeBiden Got a probl...     0     1   \n",
       "14948  @CarolyneMas @BCStevens77 @JoeBiden Not only w...     0     1   \n",
       "\n",
       "                                                original  \n",
       "14945  @CMWooly @JoeBiden @jimdicker He called for th...  \n",
       "14946  @MissyPDX @HKrassenstein @JoeBiden Got a probl...  \n",
       "14948  @CarolyneMas @BCStevens77 @JoeBiden Not only w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data = subset.loc[:,['tweet', 'trump', 'biden']]\n",
    "data['original'] = data.tweet\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Pre-Processing Pipeline\n",
    "\n",
    "Now it's time to tokenize our tweets. Here are our pre-processing steps:\n",
    "* Remove URLs\n",
    "* Remove Twitter handles\n",
    "* Remove numbers\n",
    "* Convert to lowercase\n",
    "* Remove punctuation\n",
    "* Remove repeated letters so spell check will work ('aaaaand' -> 'aand')\n",
    "* Remove non-English words\n",
    "* Remove stop words\n",
    "\n",
    "Since we're working with so many different words, I've chosen to use **lemmatization** instead of stemming for two reasons:\n",
    "1. Lemmatization accurately reduces words to true meaning\n",
    "2. Inxreased word reduction (handles synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infrared-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '@JoeBiden how is it GOING?! Looking forward to seeing you #maga'\n",
    "\n",
    "lambda x: re.sub(r\"https?:\\/\\/\\S+\", \"\", x)\n",
    "# remove twitter handles\n",
    "lambda x: re.sub(r\"@[\\d\\w_]+\", \"\", x)\n",
    "# remove numbers\n",
    "lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "# convert to lowercase\n",
    "lambda x: re.sub('[%s]'.format(re.escape(string.punctuation)), ' ', x.lower())\n",
    "# remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "lambda x: re.sub(r\"([a-z])\\1{2,}\", r'\\1', x)\n",
    "# replace consecutive spaces with one\n",
    "lambda x: ' '.join(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "democratic-connection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' how i  it going?! looking forward to  eeing you #maga'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing these before putting them in func\n",
    "\n",
    "\n",
    "tweet = '@JoeBiden how is it GOING?! Looking forward to seeing you #maga'\n",
    "\n",
    "# remove urls\n",
    "tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "# remove twitter handles\n",
    "tweet = re.sub(r\"@[\\d\\w_]+\", \"\", tweet)\n",
    "# remove numbers\n",
    "tweet = re.sub('\\w*\\d\\w*', ' ', tweet)\n",
    "# convert to lowercase\n",
    "tweet = re.sub('[%s]'.format(re.escape(string.punctuation)), ' ', tweet.lower())\n",
    "# remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "tweet = re.sub(r\"([a-z])\\1{2,}\", r'\\1', tweet)\n",
    "# replace consecutive spaces with one\n",
    "' '.join(tweet.split())\n",
    "\n",
    "# data['tweet'] = (data['tweet']\n",
    "#                  .map(no_handles)\n",
    "#                  .map(no_links)\n",
    "#                  .map(punc_lower)\n",
    "#                  .map(alphanum)\n",
    "#                  .map(no_repeats)\n",
    "#                  .map(no_dup_spaces))\n",
    "tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "interracial-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autocorrect import Speller # TOO SLOW...TRY PYSPELLCHECKER\n",
    "def tweet_tokenize(tweet, more_stop=None, more_words=None):\n",
    "    \"\"\"Get all of the tokens in a set of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        - tweets (Series, required)\n",
    "        \n",
    "        - more_stop (List, optional): additional stop words to exclude\n",
    "        \n",
    "        - more_words (List, optional): additional words to INCLUDE in dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # pre-processing pipeline\n",
    "    \n",
    "    # remove urls\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    # remove twitter handles\n",
    "#     tweet = re.sub(r\"@[\\d\\w_]+\", \"\", tweet)\n",
    "    # remove numbers\n",
    "    tweet = re.sub('\\w*\\d\\w*', ' ', tweet)\n",
    "    \n",
    "    # remove punctuation\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # remove spaces in nominee names\n",
    "    tweet = re.sub(r\"joebiden\", \"joe_biden\", tweet)\n",
    "    tweet = re.sub(r\"kamalaharris\", \"kamala_harris\", tweet)\n",
    "    tweet = re.sub(r\"donaldtrump\", \"donald_trump\", tweet)\n",
    "    tweet = re.sub(r\"mikepence\", \"mike_pence\", tweet)\n",
    "    \n",
    "    # and other popular campaign phrases\n",
    "    tweet = re.sub(r\"make america great again\", \"maga\", tweet)\n",
    "    # remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "    tweet = re.sub(r\"([a-z])\\1{2,}\", r'\\1', tweet)\n",
    "    # replace consecutive spaces with one\n",
    "    ' '.join(tweet.split())\n",
    "    \n",
    "    more_words = ['trump', 'biden', 'maga', 'bidenharris', \n",
    "                  'kamala', 'pence', 'harris', 'mike',\n",
    "                  'bidenharris2020', 'trumppence',\n",
    "                  'trumppence2020', 'usa', 'election2020',\n",
    "                  'ivoted', 'joe_biden', 'realdonaldtrump',\n",
    "                  'donald_trump', 'sleepy_joe', 'donald_trump',\n",
    "                  'mike_pence', 'kamala_harris']\n",
    "    \n",
    "    dictionary = list(words.words()) + more_words\n",
    "    dictionary = set(dictionary)\n",
    "    \n",
    "    twt = TweetTokenizer()\n",
    "    tokens = [token for token in twt.tokenize(tweet)]\n",
    "    tokens = [token for token in tokens if token in dictionary]\n",
    "    \n",
    "    # initiate stop word removal and lemmatization    \n",
    "    more_stop = ['fxhedg','fyck','fy','fxxking','give','go',\n",
    "                 'going','gonna','get','one']\n",
    "    \n",
    "    stop_words = list(stopwords.words('english')) + more_stop\n",
    "    stop = stop_words\n",
    "    stop = set(stop)\n",
    "    \n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    # implement lemmatization and stop word removal\n",
    "    tokens = [lemm.lemmatize(token) for token in tokens\n",
    "              if token.lower() not in stop]\n",
    "#     spell = Speller(lang='en')\n",
    "#     tokens = [spell(t) for t in tokens]\n",
    "\n",
    "    combined_tokens = ' '.join(tokens)\n",
    "\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "married-classification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alksfjaehf'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "lemm.lemmatize('alksfjaehf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "mediterranean-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['original'].map(tweet_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "egyptian-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>joe_biden death penalty much le responsible</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@CMWooly @JoeBiden @jimdicker He called for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14946</th>\n",
       "      <td>joe_biden got problem missy wear mask everyday...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@MissyPDX @HKrassenstein @JoeBiden Got a probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14948</th>\n",
       "      <td>joe_biden personally taking ton stock better t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@CarolyneMas @BCStevens77 @JoeBiden Not only w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet trump biden  \\\n",
       "14945        joe_biden death penalty much le responsible     0     1   \n",
       "14946  joe_biden got problem missy wear mask everyday...     0     1   \n",
       "14948  joe_biden personally taking ton stock better t...     0     1   \n",
       "\n",
       "                                                original  \n",
       "14945  @CMWooly @JoeBiden @jimdicker He called for th...  \n",
       "14946  @MissyPDX @HKrassenstein @JoeBiden Got a probl...  \n",
       "14948  @CarolyneMas @BCStevens77 @JoeBiden Not only w...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "geological-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"pickle/tweets_df_1000tw.pick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-heart",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "social-coach",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a4f48b5f8129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                              else min_df * n_doc)\n\u001b[1;32m   1212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \"max_df corresponds to < documents than min_df\")\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.05, min_df=10)\n",
    "doc_words = cv.fit_transform(data.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reliance",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(2, max_iter=115000)\n",
    "doc_topic = nmf_model.fit_transform(doc_words)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of iterations used: {nmf_model.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-matter",
   "metadata": {},
   "source": [
    "From lecture: The **doc_topic** matrix shows us the documents we started with, and how each document is made up of the 2 resulting topics. We don't know yet what the topics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-commonwealth",
   "metadata": {},
   "source": [
    "From lecture: The **topic_word** matrix shows us the 2 resulting topics, and the terms that are associated with each topic. By looking at the words below, we an figure out what the topics are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-depression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-abortion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-donna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
