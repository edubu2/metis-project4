{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-holiday",
   "metadata": {},
   "source": [
    "**Kelsey 1-1**\n",
    "\n",
    "- cleaning\n",
    "    - preprocessing until comfortable with words\n",
    "   \n",
    "- sentiment analysis on all tweets\n",
    "    - don't need to do any splitting at this stage\n",
    "    - TextBlob & VaderSentiment first, spacy if the results aren't as expected\n",
    "    \n",
    "- topic modeling\n",
    "    - decide: use all tweets (all topics) at once\n",
    "        - start here\n",
    "        - then can use these as features in the dataFrame and do splitting here\n",
    "    - or: split to trump/biden - then bot/not bot for each\n",
    "    - point here is there are multiple ways to split it\n",
    "        - no right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879311, 38)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"pickle/df_t_raw.pick\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12376</th>\n",
       "      <td>1321595921688350721</td>\n",
       "      <td>1321595556448202752</td>\n",
       "      <td>2020-10-28 23:33:16 UTC</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>23:33:16</td>\n",
       "      <td>0</td>\n",
       "      <td>467067892</td>\n",
       "      <td>billy_el_flaco</td>\n",
       "      <td>Billy Graves (Nasty Nine Podcast) ‚öæüéôÔ∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@CWFHMarquez @JoeBiden Yes, David.  They do.  üôÑ</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/Billy_el_flaco/status/1321...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'CWFHMarquez', 'name': 'David...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>1316163255958532096</td>\n",
       "      <td>1315768094921576448</td>\n",
       "      <td>2020-10-13 23:45:48 UTC</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>23:45:48</td>\n",
       "      <td>0</td>\n",
       "      <td>2857463333</td>\n",
       "      <td>iliketsheila</td>\n",
       "      <td>Sheila Schlicht</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@RobertMaguire_ @Sentient_Onion A Trump presid...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/IliketSheila/status/131616...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'RobertMaguire_', 'name': 'Ro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>1315073157456420864</td>\n",
       "      <td>1314932938455355395</td>\n",
       "      <td>2020-10-10 23:34:08 UTC</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>23:34:08</td>\n",
       "      <td>0</td>\n",
       "      <td>805102198577315840</td>\n",
       "      <td>deb_bee_2016</td>\n",
       "      <td>Bee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Biden_Army @JoeBiden No one expected him to s...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['crybabytrump', 'trumpisaloser']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/deb_bee_2016/status/131507...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Biden_Army', 'name': 'Biden ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id               created_at  \\\n",
       "12376  1321595921688350721  1321595556448202752  2020-10-28 23:33:16 UTC   \n",
       "7608   1316163255958532096  1315768094921576448  2020-10-13 23:45:48 UTC   \n",
       "8808   1315073157456420864  1314932938455355395  2020-10-10 23:34:08 UTC   \n",
       "\n",
       "             date      time  timezone             user_id        username  \\\n",
       "12376  2020-10-28  23:33:16         0           467067892  billy_el_flaco   \n",
       "7608   2020-10-13  23:45:48         0          2857463333    iliketsheila   \n",
       "8808   2020-10-10  23:34:08         0  805102198577315840    deb_bee_2016   \n",
       "\n",
       "                                        name place  \\\n",
       "12376  Billy Graves (Nasty Nine Podcast) ‚öæüéôÔ∏è   NaN   \n",
       "7608                         Sheila Schlicht   NaN   \n",
       "8808                                     Bee   NaN   \n",
       "\n",
       "                                                   tweet language mentions  \\\n",
       "12376    @CWFHMarquez @JoeBiden Yes, David.  They do.  üôÑ       en       []   \n",
       "7608   @RobertMaguire_ @Sentient_Onion A Trump presid...       en       []   \n",
       "8808   @Biden_Army @JoeBiden No one expected him to s...       en       []   \n",
       "\n",
       "      urls photos  replies_count  retweets_count  likes_count  \\\n",
       "12376   []     []              0               0            0   \n",
       "7608    []     []              0               0            0   \n",
       "8808    []     []              1               0            1   \n",
       "\n",
       "                                hashtags cashtags  \\\n",
       "12376                                 []       []   \n",
       "7608                                  []       []   \n",
       "8808   ['crybabytrump', 'trumpisaloser']       []   \n",
       "\n",
       "                                                    link  retweet quote_url  \\\n",
       "12376  https://twitter.com/Billy_el_flaco/status/1321...    False       NaN   \n",
       "7608   https://twitter.com/IliketSheila/status/131616...    False       NaN   \n",
       "8808   https://twitter.com/deb_bee_2016/status/131507...    False       NaN   \n",
       "\n",
       "       video thumbnail  near  geo  source  user_rt_id  user_rt  retweet_id  \\\n",
       "12376      0       NaN   NaN  NaN     NaN         NaN      NaN         NaN   \n",
       "7608       0       NaN   NaN  NaN     NaN         NaN      NaN         NaN   \n",
       "8808       0       NaN   NaN  NaN     NaN         NaN      NaN         NaN   \n",
       "\n",
       "                                                reply_to  retweet_date  \\\n",
       "12376  [{'screen_name': 'CWFHMarquez', 'name': 'David...           NaN   \n",
       "7608   [{'screen_name': 'RobertMaguire_', 'name': 'Ro...           NaN   \n",
       "8808   [{'screen_name': 'Biden_Army', 'name': 'Biden ...           NaN   \n",
       "\n",
       "       translate  trans_src  trans_dest  biden  trump  \n",
       "12376        NaN        NaN         NaN      1      0  \n",
       "7608         NaN        NaN         NaN      0      1  \n",
       "8808         NaN        NaN         NaN      1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-muscle",
   "metadata": {},
   "source": [
    "Now let's create a subset, containing the same amount of Trump tweets as Biden tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aging-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.trump == 0) & (df.biden == 1)\n",
    "biden_tweets = df[mask]\n",
    "\n",
    "mask = (df.trump == 1) & (df.biden == 0)\n",
    "trump_tweets = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recreational-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>mentions</th>\n",
       "      <th>urls</th>\n",
       "      <th>photos</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>link</th>\n",
       "      <th>retweet</th>\n",
       "      <th>quote_url</th>\n",
       "      <th>video</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>1312540751730028545</td>\n",
       "      <td>1312460408192724992</td>\n",
       "      <td>2020-10-03 23:51:15 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:51:15</td>\n",
       "      <td>0</td>\n",
       "      <td>958208381088493569</td>\n",
       "      <td>naname1961</td>\n",
       "      <td>Naname üåäüåäüåä üÜò</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@JoeBiden @minnielobban Can‚Äôt come fast enough!</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/Naname1961/status/13125407...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'JoeBiden', 'name': 'Joe Bide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>1312537654248968193</td>\n",
       "      <td>1312537654248968193</td>\n",
       "      <td>2020-10-03 23:38:57 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:38:57</td>\n",
       "      <td>0</td>\n",
       "      <td>881307775355068416</td>\n",
       "      <td>la_krag</td>\n",
       "      <td>üá∫üá∏LA_KRAGüá∫üá∏</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@JoeBiden will destroy America as we know it!</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/LA_Krag/status/13125376542...</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/TarekFatah/status/13124403...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>1312531236405956609</td>\n",
       "      <td>1312460408192724992</td>\n",
       "      <td>2020-10-03 23:13:27 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:13:27</td>\n",
       "      <td>0</td>\n",
       "      <td>1141498926</td>\n",
       "      <td>bison_stew</td>\n",
       "      <td>Bison Stew</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@colleenwmobile @DeanSpicyReacts @Himod8583386...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/bison_stew/status/13125312...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'colleenwmobile', 'name': 'Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id               created_at  \\\n",
       "2323   1312540751730028545  1312460408192724992  2020-10-03 23:51:15 UTC   \n",
       "5763   1312537654248968193  1312537654248968193  2020-10-03 23:38:57 UTC   \n",
       "13343  1312531236405956609  1312460408192724992  2020-10-03 23:13:27 UTC   \n",
       "\n",
       "             date      time timezone             user_id    username  \\\n",
       "2323   2020-10-03  23:51:15        0  958208381088493569  naname1961   \n",
       "5763   2020-10-03  23:38:57        0  881307775355068416     la_krag   \n",
       "13343  2020-10-03  23:13:27        0          1141498926  bison_stew   \n",
       "\n",
       "               name place                                              tweet  \\\n",
       "2323   Naname üåäüåäüåä üÜò   NaN    @JoeBiden @minnielobban Can‚Äôt come fast enough!   \n",
       "5763    üá∫üá∏LA_KRAGüá∫üá∏   NaN      @JoeBiden will destroy America as we know it!   \n",
       "13343    Bison Stew   NaN  @colleenwmobile @DeanSpicyReacts @Himod8583386...   \n",
       "\n",
       "      language mentions urls photos replies_count retweets_count likes_count  \\\n",
       "2323        en       []   []     []             0              0           0   \n",
       "5763        en       []   []     []             0              0           0   \n",
       "13343       en       []   []     []             0              0           1   \n",
       "\n",
       "      hashtags cashtags                                               link  \\\n",
       "2323        []       []  https://twitter.com/Naname1961/status/13125407...   \n",
       "5763        []       []  https://twitter.com/LA_Krag/status/13125376542...   \n",
       "13343       []       []  https://twitter.com/bison_stew/status/13125312...   \n",
       "\n",
       "      retweet                                          quote_url video  \\\n",
       "2323    False                                                NaN     0   \n",
       "5763    False  https://twitter.com/TarekFatah/status/13124403...     0   \n",
       "13343   False                                                NaN     0   \n",
       "\n",
       "      thumbnail near  geo source user_rt_id user_rt retweet_id  \\\n",
       "2323        NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "5763        NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "13343       NaN  NaN  NaN    NaN        NaN     NaN        NaN   \n",
       "\n",
       "                                                reply_to retweet_date  \\\n",
       "2323   [{'screen_name': 'JoeBiden', 'name': 'Joe Bide...          NaN   \n",
       "5763                                                  []          NaN   \n",
       "13343  [{'screen_name': 'colleenwmobile', 'name': 'Co...          NaN   \n",
       "\n",
       "      translate trans_src trans_dest biden trump  \n",
       "2323        NaN       NaN        NaN     1     0  \n",
       "5763        NaN       NaN        NaN     1     0  \n",
       "13343       NaN       NaN        NaN     1     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = pd.DataFrame(columns=df.columns)\n",
    "subset = subset.append(biden_tweets.tail(10000))\n",
    "subset = subset.append(trump_tweets.tail(10000))\n",
    "\n",
    "subset.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@capriaaf @JoeBiden Plenty of results for #Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Changinglenses @greger_mary @JRubinBlogger @G...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inside a Biden v. Trump marriage: \"you woke me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  trump  biden\n",
       "0  @capriaaf @JoeBiden Plenty of results for #Tru...      1      1\n",
       "1  @Changinglenses @greger_mary @JRubinBlogger @G...      0      1\n",
       "2  Inside a Biden v. Trump marriage: \"you woke me...      1      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data = df.loc[:,['tweet', 'trump', 'biden']]\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-headset",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We'll start small by simply removing numbers & punctuation and converting each tweet to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "democratic-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove urls\n",
    "no_links = lambda x: re.sub(r\"https?:\\/\\/\\S+\", \"\", x)\n",
    "# remove twitter handles\n",
    "no_handles = lambda x: re.sub(r\"@[\\d\\w_]+\", \"\", x)\n",
    "# remove numbers\n",
    "alphanum = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "# convert to lowercase\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "# remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "no_repeats = lambda x: re.sub(r\"([a-z])\\1{2,}\", r'\\1', x)\n",
    "# replace consecutive spaces with one\n",
    "no_dup_spaces = lambda x: ' '.join(x.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continent-sense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plenty of results for trumpcrimefamily and tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@capriaaf @JoeBiden Plenty of results for #Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he left washington before impeachment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@Changinglenses @greger_mary @JRubinBlogger @G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inside a biden v trump marriage you woke me up...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Inside a Biden v. Trump marriage: \"you woke me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  trump  biden  \\\n",
       "0  plenty of results for trumpcrimefamily and tru...      1      1   \n",
       "1              he left washington before impeachment      0      1   \n",
       "2  inside a biden v trump marriage you woke me up...      1      1   \n",
       "\n",
       "                                            original  \n",
       "0  @capriaaf @JoeBiden Plenty of results for #Tru...  \n",
       "1  @Changinglenses @greger_mary @JRubinBlogger @G...  \n",
       "2  Inside a Biden v. Trump marriage: \"you woke me...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['original'] = data.tweet\n",
    "\n",
    "data['tweet'] = (data['tweet']\n",
    "                 .map(no_handles)\n",
    "                 .map(no_links)\n",
    "                 .map(punc_lower)\n",
    "                 .map(alphanum)\n",
    "                 .map(no_repeats)\n",
    "                 .map(no_dup_spaces))\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Now it's time to tokenize our tweets. Here, we'll implement NLTK's tokenizer, stop word removal, Porter Stemming, and spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "interracial-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autocorrect import Speller # TOO SLOW...TRY PYSPELLCHECKER\n",
    "def tweet_tokenize(tweets, more_stop=None):\n",
    "    \"\"\"Get all of the tokens in a set of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        - tweets (Series, required)\n",
    "        \n",
    "        - more_stop (List, optional): additional stop words to exclude\n",
    "    \n",
    "    \"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    tokens = [token for tweet in tweets for token in twt.tokenize(tweet)]\n",
    "    # combine stop words and punctuation\n",
    "    puncs = [c for c in string.punctuation if c not in [\"#\", \":\"]]\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    if more_stop is not None:\n",
    "        [stop_words.append(w) for w in more_stop]\n",
    "        \n",
    "    stop = stop_words + puncs + ['‚Äù']\n",
    "    \n",
    "    lemm = WordNetLemmatizer()\n",
    "    tokens = [ lemm.lemmatize(token) for tweet in tweets\n",
    "              for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "#     spell = Speller(lang='en')\n",
    "#     tokens = [spell(t) for t in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "human-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stop = [\n",
    "    'fxhedg',\n",
    "    'fyck',\n",
    "    'fy',\n",
    "    'fxxking',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "searching-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tweet_tokenize(data.tweet,more_stop=more_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "excess-thong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11127421"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ready-brooks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178862"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-forest",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "plastic-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11127421, 7609)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.05, min_df=100)\n",
    "doc_words = cv.fit_transform(tokens)\n",
    "doc_words.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-plasma",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(2, max_iter=1500)\n",
    "doc_topic = nmf_model.fit_transform(doc_words)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of iterations used: {nmf_model.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-differential",
   "metadata": {},
   "source": [
    "From lecture: The **doc_topic** matrix shows us the documents we started with, and how each document is made up of the 2 resulting topics. We don't know yet what the topics are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-basement",
   "metadata": {},
   "source": [
    "From lecture: The **topic_word** matrix shows us the 2 resulting topics, and the terms that are associated with each topic. By looking at the words below, we an figure out what the topics are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-client",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-addition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
