{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "import spacy\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "# import contextualSpellCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "large-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-holiday",
   "metadata": {},
   "source": [
    "**Kelsey 1-1**\n",
    "\n",
    "- cleaning\n",
    "    - preprocessing until comfortable with words\n",
    "   \n",
    "- sentiment analysis on all tweets\n",
    "    - don't need to do any splitting at this stage\n",
    "    - TextBlob & VaderSentiment first, spacy if the results aren't as expected\n",
    "    \n",
    "- topic modeling\n",
    "    - decide: use all tweets (all topics) at once\n",
    "        - start here\n",
    "        - then can use these as features in the dataFrame and do splitting here\n",
    "    - or: split to trump/biden - then bot/not bot for each\n",
    "    - point here is there are multiple ways to split it\n",
    "        - no right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879311, 38)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"pickle/df_t_raw.pick\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "domestic-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
       "       'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count',\n",
       "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
       "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
       "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
       "       'trans_dest', 'biden', 'trump'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patent-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "438106"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.username.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-muscle",
   "metadata": {},
   "source": [
    "Now let's create a subset, containing the same amount of Trump tweets as Biden tweets as tweets mentioning both candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.53 ms, sys: 227 Âµs, total: 8.76 ms\n",
      "Wall time: 7.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[My, name, is, Elliot, .]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "[t for t in nlp(\"My name is Elliot.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi INTJ ROOT\n",
      ", PUNCT punct\n",
      "readers NOUN npadvmod\n",
      "! PUNCT punct\n",
      "My PRON poss\n",
      "name NOUN nsubj\n",
      "is AUX ROOT\n",
      "Elliot PROPN compound\n",
      "Wilens PROPN attr\n",
      ". PUNCT punct\n",
      "I PRON nsubj\n",
      "love VERB ROOT\n",
      "mountains NOUN dobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# spacy practice\n",
    "\n",
    "text = 'Hi, readers! My name is Elliot Wilens. I love mountains.'\n",
    "\n",
    "for t in nlp(text):\n",
    "    print(t, t.pos_, t.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "played-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hi, readers! My name is Elliot Wilens. I love mountains."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-tribute",
   "metadata": {},
   "source": [
    "## Initiate Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "restricted-continent",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-25000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/home/wilensel/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -25000",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d88b566f92fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wilensel/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wilensel/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -25000"
     ]
    }
   ],
   "source": [
    "df = df.copy()[-25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spacy_doc'] = list(nlp.pipe(df.tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-violin",
   "metadata": {},
   "source": [
    "## Now let's split our data into biden & trump tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.trump == 0) & (df.biden == 1)\n",
    "biden_tweets = df[mask].tail(500)\n",
    "\n",
    "mask = (df.trump == 1) & (df.biden == 0)\n",
    "trump_tweets = df[mask].tail(500)\n",
    "\n",
    "# mask = (df.trump == 1) & (df.biden == 1)\n",
    "# both_tweets = df[mask].tail(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-poker",
   "metadata": {},
   "source": [
    "Now, let's use spaCy's `pipe` method in order to process multiple documents in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_adj = [token.text.lower() for doc in biden_tweets.tweet.spacy_doc for token in doc if token.pos_=='ADJ']\n",
    "trump_adj = [token.text.lower() for doc in trump_tweets.tweet.spacy_doc for token in doc if token.pos_=='ADJ']\n",
    "\n",
    "biden_noun = [token.text.lower() for doc in biden_tweets.tweet.spacy_doc for token in doc if token.pos_=='NOUN']\n",
    "trump_noun = [token.text.lower() for doc in trump_tweets.tweet.spacy_doc for token in doc if token.pos_=='NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-russian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-lecture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-israeli",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
