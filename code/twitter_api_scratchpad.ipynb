{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-montana",
   "metadata": {},
   "source": [
    "## Implementing Chris Doenlen's 'Bot Or Not' Python Module\n",
    "\n",
    "Everything from `twitter_funcs.py` was cloned from Chris' [repository](https://github.com/scrapfishies/twitter-bot-detection).\n",
    "\n",
    "I will use this to label each user as 'bot' (boolean 1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cellular-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from twitter_funcs import *\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import tweepy\n",
    "\n",
    "from datetime import datetime\n",
    "from secrets import api_secret_key, api_key, bearer_token\n",
    "import re\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "artificial-plant",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"pickle/balanced_nov2_tweets.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-location",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144000, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>1323379284434669568</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:39:43</td>\n",
       "      <td>2820503362</td>\n",
       "      <td>artistacriseida</td>\n",
       "      <td>All these articles showing that Biden is in th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323414585995526144</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>1312487180258820096</td>\n",
       "      <td>annapieters17</td>\n",
       "      <td>@FoxNews Lady Gaga’s a nobody. Can’t figure ou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323414585232293888</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>2335763630</td>\n",
       "      <td>kylechwatt</td>\n",
       "      <td>@The_Grupp “It is purely a fortuity that this ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "181142  1323379284434669568 2020-11-02  21:39:43           2820503362   \n",
       "0       1323414585995526144 2020-11-02  23:59:59  1312487180258820096   \n",
       "4       1323414585232293888 2020-11-02  23:59:59           2335763630   \n",
       "\n",
       "               username                                              tweet  \\\n",
       "181142  artistacriseida  All these articles showing that Biden is in th...   \n",
       "0         annapieters17  @FoxNews Lady Gaga’s a nobody. Can’t figure ou...   \n",
       "4            kylechwatt  @The_Grupp “It is purely a fortuity that this ...   \n",
       "\n",
       "       hashtags  trump  biden  \n",
       "181142       []  False   True  \n",
       "0            []  False   True  \n",
       "4            []  False   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enclosed-pepper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = list(data.user_id.unique())\n",
    "len(user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-husband",
   "metadata": {},
   "source": [
    "I'm getting a rate limit error. according to twitter site, I can lookup 300 users per 15 minutes. Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "covered-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(user_ids, n):\n",
    "    \"\"\"Yield successive n-sized chunks from user_ids (iterable).\"\"\"\n",
    "    lst = list(user_ids)\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "    \n",
    "user_id_chunks = list(chunks(user_ids, n=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-justice",
   "metadata": {},
   "source": [
    "Here's where we'll implement Chris Doenlen's 'Bot or Not' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "verifieds = {}\n",
    "bot_probas = {}\n",
    "time.sleep(15*60+30)\n",
    "\n",
    "with open(\"bot_model.pick\", \"rb\") as read_file:\n",
    "    xgb_model = pickle.load(read_file)\n",
    "\n",
    "csv_file = open(\"../data/user_stats.csv\", \"w+\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"user_id\", \"bot_proba\", \"verified\"])\n",
    "for chunk in user_id_chunks:\n",
    "    for user_id in chunk:\n",
    "        print(f\"Preparing chunk. Num users: {len(chunk)}\")\n",
    "        \n",
    "        auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "        api = tweepy.API(auth)\n",
    "        \n",
    "        try: # Gather features for bot/not bot model\n",
    "            # Get user information from screen name\n",
    "            user = api.get_user(user_id)\n",
    "\n",
    "            # account features to return for predicton\n",
    "            account_age_days = (datetime.now() - user.created_at).days\n",
    "            verified = user.verified # will also use this in our data\n",
    "            geo_enabled = user.geo_enabled\n",
    "            default_profile = user.default_profile\n",
    "            default_profile_image = user.default_profile_image\n",
    "            favourites_count = user.favourites_count\n",
    "            followers_count = user.followers_count\n",
    "            friends_count = user.friends_count\n",
    "            statuses_count = user.statuses_count\n",
    "            average_tweets_per_day = np.round(statuses_count / account_age_days, 3)\n",
    "\n",
    "            # manufactured features\n",
    "            hour_created = int(user.created_at.strftime(\"%H\"))\n",
    "            network = np.round(np.log(1 + friends_count) * np.log(1 + followers_count), 3)\n",
    "            tweet_to_followers = np.round(\n",
    "                np.log(1 + statuses_count) * np.log(1 + followers_count), 3\n",
    "            )\n",
    "            follower_acq_rate = np.round(\n",
    "                np.log(1 + (followers_count / account_age_days)), 3\n",
    "            )\n",
    "            friends_acq_rate = np.round(np.log(1 + (friends_count / account_age_days)), 3)\n",
    "\n",
    "            # organizing list to be returned\n",
    "            account_features = [\n",
    "                verified, hour_created,geo_enabled,default_profile,default_profile_image,favourites_count,\n",
    "                followers_count,friends_count,statuses_count,average_tweets_per_day,network,tweet_to_followers,\n",
    "                follower_acq_rate,friends_acq_rate]\n",
    "\n",
    "            if account_features == np.nan:\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                user_m = np.matrix(account_features)\n",
    "                proba = np.round(xgb_model.predict_proba(user_m)[:, 1][0] * 100, 2)\n",
    "                verified = account_features[0]\n",
    "\n",
    "        except:\n",
    "            print(f'error encountered, skipping user {user_id}')\n",
    "            proba = np.nan\n",
    "            verified = np.nan\n",
    "        \n",
    "        csv_writer.writerow([user_id, proba, verified])\n",
    "        print(\"Chunk complete. Waiting 15 minutes.\")\n",
    "        time.sleep(15*60+1)\n",
    "\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bot_proba'] = data['user_id'].map(bot_probas)\n",
    "data['verifieds'] = data['user_id'].map(is_verified)\n",
    "data.to_pickle(\"pickle/tw_proba_verif.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "verifieds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['verified'] = data['user_id'].map(verifieds)\n",
    "data['bot_proba'] = data['user_id'].map(bot_probas)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
