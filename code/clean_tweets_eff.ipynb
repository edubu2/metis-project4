{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/balanced_nov2_tweets.pick\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>1323379284434669568</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:39:43</td>\n",
       "      <td>2820503362</td>\n",
       "      <td>artistacriseida</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won‚Äôt matter on Election Day. Hillary was also in the lead last election, just do your part.   ‚ÅΩ·∂†·µò·∂ú·µè ·µó ≥·µò·µê·µñ‚Åæ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323414585995526144</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>1312487180258820096</td>\n",
       "      <td>annapieters17</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@FoxNews Lady Gaga‚Äôs a nobody. Can‚Äôt figure out her own life and can‚Äôt even see nobody can help Biden. He‚Äôs out of the game from the day he gets in the game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323414585232293888</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>2335763630</td>\n",
       "      <td>kylechwatt</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@The_Grupp ‚ÄúIt is purely a fortuity that this isn‚Äôt one of the great mass casualty events in American history,‚Äù Ron Klain, who was Biden‚Äôs chief of staff at the time, said of H1N1 in 2019.‚Äù   https://t.co/Umi317supK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "181142  1323379284434669568 2020-11-02  21:39:43           2820503362   \n",
       "0       1323414585995526144 2020-11-02  23:59:59  1312487180258820096   \n",
       "4       1323414585232293888 2020-11-02  23:59:59           2335763630   \n",
       "\n",
       "               username hashtags  trump  biden  \\\n",
       "181142  artistacriseida       []  False   True   \n",
       "0         annapieters17       []  False   True   \n",
       "4            kylechwatt       []  False   True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                        original  \n",
       "181142  All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won‚Äôt matter on Election Day. Hillary was also in the lead last election, just do your part.   ‚ÅΩ·∂†·µò·∂ú·µè ·µó ≥·µò·µê·µñ‚Åæ  \n",
       "0                                                                                                                  @FoxNews Lady Gaga‚Äôs a nobody. Can‚Äôt figure out her own life and can‚Äôt even see nobody can help Biden. He‚Äôs out of the game from the day he gets in the game.  \n",
       "4                                                        @The_Grupp ‚ÄúIt is purely a fortuity that this isn‚Äôt one of the great mass casualty events in American history,‚Äù Ron Klain, who was Biden‚Äôs chief of staff at the time, said of H1N1 in 2019.‚Äù   https://t.co/Umi317supK  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data['original'] = data.tweet\n",
    "data.drop(columns='tweet', inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Pre-Processing Pipeline\n",
    "\n",
    "Now it's time to tokenize our tweets. Here are our pre-processing steps:\n",
    "* Remove URLs\n",
    "* Remove Twitter handles\n",
    "* Remove numbers\n",
    "* Convert to lowercase\n",
    "* Remove punctuation\n",
    "* Remove repeated letters so spell check will work ('aaaaand' -> 'aand')\n",
    "* Remove non-English words\n",
    "* Remove stop words\n",
    "\n",
    "Since we're working with so many different words, I've chosen to use **lemmatization** instead of stemming for two reasons:\n",
    "1. Lemmatization accurately reduces words to true meaning\n",
    "2. Inxreased word reduction (handles synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "motivated-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download() # must run first time (download 'popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abstract-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom word dictionaries\n",
    "from more_words import more_words as custom_words\n",
    "from stop_words import stop_words as custom_stop_words\n",
    "from bigrams import bigrams\n",
    "\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    \"\"\"Pre-processing pipeline.\"\"\"\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"u\\.s\\. \", \"usa\", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\w*\\d\\w*', ' ', tweet)\n",
    "    tweet = re.sub(r'\\.{2,6}', ' ', tweet)\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    tweet = re.sub(r\"([a-z])\\1{2,5}\", r'\\1', tweet)\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    \n",
    "    for old, new in bigrams:\n",
    "        tweet = re.sub(old, new, tweet) # ex: ('white house', 'whitehouse')\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "def tokenize(tweet, all_words, stop_words):\n",
    "    \"\"\"\n",
    "    Returns all of the tokens in a cleaned tweet\n",
    "    Parameters:\n",
    "        - tweet (Series, required)\n",
    "        - stop_words (set, required)\n",
    "        - all_words (set, required) \n",
    "        \n",
    "    Note:\n",
    "        - any words not included in all_words here will be\n",
    "          removed from tokens (including bigrams)\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet = clean_tweet(tweet)\n",
    "    \n",
    "    twt = TweetTokenizer()    \n",
    "    lemm = WordNetLemmatizer()  \n",
    "    # lemmatize tokens & remove stop words\n",
    "    tokens = [lemm.lemmatize(token) for token in twt.tokenize(tweet) if token not in stop_words]\n",
    "    # only include words that are in our customized list of words\n",
    "    tokens = [token for token in tokens if token in all_words]\n",
    "    combined_tokens = ' '.join(tokens)\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "def clean_and_tokenize(original_tweets):\n",
    "    \"\"\"\n",
    "    Efficiently cleans, tokenizes, lemmatizes, and implements customized\n",
    "    bigrams on a list of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        original_tweets (required, pd.Series)\n",
    "    \n",
    "    Returns:\n",
    "        cleaned, tokenized tweets (np.array)\n",
    "    \"\"\"\n",
    "    tweet_array = original_tweets.to_numpy()\n",
    "\n",
    "    all_words = list(words.words('en')) + custom_words\n",
    "    stop_words = set(list(stopwords.words('english')) + custom_stop_words)\n",
    "    \n",
    "    for _, new in bigrams:\n",
    "        all_words.append(new)\n",
    "\n",
    "    all_words = set(all_words)\n",
    "    print(\"num words: \", len(all_words))\n",
    "    print(\"num stop words: \", len(stop_words))\n",
    "    \n",
    "    clean_tweets = [tokenize(tweet, all_words, stop_words) for tweet in tweet_array]\n",
    "    \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cleared-stress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236110\n",
      "num stop words:  393\n",
      "CPU times: user 38.8 s, sys: 107 ms, total: 39 s\n",
      "Wall time: 39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['tweet'] = clean_and_tokenize(data.original)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loose-audience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60778, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_tokens'] = data['tweet'].str.count(' ') + 1\n",
    "\n",
    "mask = data['num_tokens'] >= 5\n",
    "data_minlen = data[mask]\n",
    "data_minlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aerial-consideration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Trump Tweets 32084\n",
      "\n",
      " Biden Tweets: 28694\n"
     ]
    }
   ],
   "source": [
    "mask = (data_minlen.trump == 0) & (data_minlen.biden == 1)\n",
    "biden = data_minlen[mask]\n",
    "mask = (data_minlen.trump ==1) & (data_minlen.biden == 0)\n",
    "trump = data_minlen[mask]\n",
    "\n",
    "print(f\"\\n Trump Tweets {len(trump)}\\n\\n Biden Tweets: {len(biden)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"pickle/n2_tokenized_eff.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>@MeghanMcCain you must be so proud of your beloved trump trash supporters!</td>\n",
       "      <td>beloved trash supporter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>@lucyg127 ewwwww the people at my school where trump stuff to school all the time i‚Äôm just there like üòî</td>\n",
       "      <td>school stuff school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76582</th>\n",
       "      <td>Trump never talks about the terrible pain that the families of the 230,000 dead from his COVID are going through.</td>\n",
       "      <td>talk pain family dead covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60215</th>\n",
       "      <td>NEW AD: Joe Biden uses 2 Live Crew classic \"Get the Fuck Out of My House\" to encourage voting.</td>\n",
       "      <td>us crew classic house voting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63072</th>\n",
       "      <td>‚ÄúBUT BIDEN‚ÄôS LEADING IN THE POLLS‚Äù.....FAMOUS LAST WORDS  https://t.co/U1zMF5yMfS</td>\n",
       "      <td>leading poll famous word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74948</th>\n",
       "      <td>@All_Prays @th3damage_ @LeighEllis @turbotax Ok genius; tell me if this impresses you, Lebron has a lifetime contract from Nike that will pay him a billion dollars requiring virtually nothing from him. Use whatever discount rate you want, Trump would hock all 5? of his kids for something half as valuable.</td>\n",
       "      <td>genius impress lifetime contract pay billion dollar virtually use whatever discount rate hock something half valuable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>@GOP @realDonaldTrump An adorable child was taught about voting and the election at school.   The teacher asked do you know why your parents are voting tomorrow.  The child answered ‚Äú to kick the Trump out‚Äù</td>\n",
       "      <td>adorable child taught voting school teacher parent voting child kick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71542</th>\n",
       "      <td>Imagine this scenario:  President: Joe Biden Vice President: Kamala Harris Attorney General: Adam Schiff Secretary of State: Hillary Clinton Treasury Secretary: Elizabeth Warren COVID-19 Czar: Andrew Cuomo Green New Deal Board: AOC Constitution Review Board: Beto O'Rourke  #VOTE</td>\n",
       "      <td>scenario vicepresident attorneygeneral secretary hillaryclinton treasury secretary warren covid czar green deal board constitution review board vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72652</th>\n",
       "      <td>@VotingBlueInTX Fauci has made it very clear that we are not turning the corner and in fact we couldn't be in a worse position for going into winter.  This complete contradicts Trump's campaign message, and we know what he does when someone in Government takes a position against this monster.</td>\n",
       "      <td>anthonyfauci clear turning corner fact worse position winter complete trump campaign government take position monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12665</th>\n",
       "      <td>@sapphiresdust #Cult   Hard to imagine, but they see God's Will in everything he says and does or demands be done.  Trump may as well be the Second Coming.</td>\n",
       "      <td>cult hard god say demand may second coming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                 original  \\\n",
       "49154                                                                                                                                                                                                                                          @MeghanMcCain you must be so proud of your beloved trump trash supporters!   \n",
       "12212                                                                                                                                                                                                             @lucyg127 ewwwww the people at my school where trump stuff to school all the time i‚Äôm just there like üòî   \n",
       "76582                                                                                                                                                                                                   Trump never talks about the terrible pain that the families of the 230,000 dead from his COVID are going through.   \n",
       "60215                                                                                                                                                                                                                      NEW AD: Joe Biden uses 2 Live Crew classic \"Get the Fuck Out of My House\" to encourage voting.   \n",
       "63072                                                                                                                                                                                                                                   ‚ÄúBUT BIDEN‚ÄôS LEADING IN THE POLLS‚Äù.....FAMOUS LAST WORDS  https://t.co/U1zMF5yMfS   \n",
       "...                                                                                                                                                                                                                                                                                                                   ...   \n",
       "74948  @All_Prays @th3damage_ @LeighEllis @turbotax Ok genius; tell me if this impresses you, Lebron has a lifetime contract from Nike that will pay him a billion dollars requiring virtually nothing from him. Use whatever discount rate you want, Trump would hock all 5? of his kids for something half as valuable.   \n",
       "3818                                                                                                       @GOP @realDonaldTrump An adorable child was taught about voting and the election at school.   The teacher asked do you know why your parents are voting tomorrow.  The child answered ‚Äú to kick the Trump out‚Äù   \n",
       "71542                             Imagine this scenario:  President: Joe Biden Vice President: Kamala Harris Attorney General: Adam Schiff Secretary of State: Hillary Clinton Treasury Secretary: Elizabeth Warren COVID-19 Czar: Andrew Cuomo Green New Deal Board: AOC Constitution Review Board: Beto O'Rourke  #VOTE   \n",
       "72652               @VotingBlueInTX Fauci has made it very clear that we are not turning the corner and in fact we couldn't be in a worse position for going into winter.  This complete contradicts Trump's campaign message, and we know what he does when someone in Government takes a position against this monster.   \n",
       "12665                                                                                                                                                         @sapphiresdust #Cult   Hard to imagine, but they see God's Will in everything he says and does or demands be done.  Trump may as well be the Second Coming.   \n",
       "\n",
       "                                                                                                                                                      tweet  \n",
       "49154                                                                                                                               beloved trash supporter  \n",
       "12212                                                                                                                                   school stuff school  \n",
       "76582                                                                                                                           talk pain family dead covid  \n",
       "60215                                                                                                                          us crew classic house voting  \n",
       "63072                                                                                                                              leading poll famous word  \n",
       "...                                                                                                                                                     ...  \n",
       "74948                                 genius impress lifetime contract pay billion dollar virtually use whatever discount rate hock something half valuable  \n",
       "3818                                                                                   adorable child taught voting school teacher parent voting child kick  \n",
       "71542  scenario vicepresident attorneygeneral secretary hillaryclinton treasury secretary warren covid czar green deal board constitution review board vote  \n",
       "72652                                 anthonyfauci clear turning corner fact worse position winter complete trump campaign government take position monster  \n",
       "12665                                                                                                            cult hard god say demand may second coming  \n",
       "\n",
       "[15 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['original', 'tweet']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geological-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/tweets_df_5000tw.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confused-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236110\n",
      "num stop words:  393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tweet votingrights continuous breakdown']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'tweet tokenize me please mr. biden helloaskldjalksfj I  pence    voting rights am asking for a favor continuous breakdown American Americans'\n",
    "\n",
    "clean_and_tokenize(pd.Series(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "growing-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organization'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "lemm.lemmatize('organizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brief-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/n2_tokenized_min4.pick\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
