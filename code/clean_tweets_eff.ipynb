{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/balanced_nov2_tweets.pick\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>1323379284434669568</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:39:43</td>\n",
       "      <td>2820503362</td>\n",
       "      <td>artistacriseida</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323414585995526144</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>1312487180258820096</td>\n",
       "      <td>annapieters17</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323414585232293888</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>2335763630</td>\n",
       "      <td>kylechwatt</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "181142  1323379284434669568 2020-11-02  21:39:43           2820503362   \n",
       "0       1323414585995526144 2020-11-02  23:59:59  1312487180258820096   \n",
       "4       1323414585232293888 2020-11-02  23:59:59           2335763630   \n",
       "\n",
       "               username hashtags  trump  biden  \\\n",
       "181142  artistacriseida       []  False   True   \n",
       "0         annapieters17       []  False   True   \n",
       "4            kylechwatt       []  False   True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                        original  \n",
       "181142  All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾  \n",
       "0                                                                                                                  @FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.  \n",
       "4                                                        @The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data['original'] = data.tweet\n",
    "data.drop(columns='tweet', inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Pre-Processing Pipeline\n",
    "\n",
    "Now it's time to tokenize our tweets. Here are our pre-processing steps:\n",
    "* Remove URLs\n",
    "* Remove Twitter handles\n",
    "* Remove numbers\n",
    "* Convert to lowercase\n",
    "* Remove punctuation\n",
    "* Remove repeated letters so spell check will work ('aaaaand' -> 'aand')\n",
    "* Remove non-English words\n",
    "* Remove stop words\n",
    "\n",
    "Since we're working with so many different words, I've chosen to use **lemmatization** instead of stemming for two reasons:\n",
    "1. Lemmatization accurately reduces words to true meaning\n",
    "2. Inxreased word reduction (handles synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "motivated-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download() # must run first time (download 'popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "catholic-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom word dictionaries\n",
    "from more_words import more_words as custom_words\n",
    "from stop_words import stop_words as custom_stop_words\n",
    "from bigrams import bigrams\n",
    "\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    \"\"\"Pre-processing pipeline.\"\"\"\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"u\\.s\\. \", \"usa\", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\w*\\d\\w*', ' ', tweet)\n",
    "    tweet = re.sub(r'\\.{2,6}', ' ', tweet)\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    tweet = re.sub(r\"([a-z])\\1{2,5}\", r'\\1', tweet)\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    \n",
    "    for old, new in bigrams:\n",
    "        tweet = re.sub(old, new, tweet) # ex: ('white house', 'whitehouse')\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "def tokenize(tweet, all_words, stop_words):\n",
    "    \"\"\"\n",
    "    Returns all of the tokens in a cleaned tweet\n",
    "    Parameters:\n",
    "        - tweet (Series, required)\n",
    "        - stop_words (set, required)\n",
    "        - all_words (set, required) \n",
    "        \n",
    "    Note:\n",
    "        - any words not included in all_words here will be\n",
    "          removed from tokens (including bigrams)\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet = clean_tweet(tweet)\n",
    "    \n",
    "    twt = TweetTokenizer()    \n",
    "    lemm = WordNetLemmatizer()  \n",
    "    # lemmatize tokens & remove stop words\n",
    "    tokens = [lemm.lemmatize(token) for token in twt.tokenize(tweet) if token not in stop_words]\n",
    "    # only include words that are in our customized list of words\n",
    "    tokens = [token for token in tokens if token in all_words]\n",
    "    combined_tokens = ' '.join(tokens)\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "def clean_and_tokenize(original_tweets):\n",
    "    \"\"\"\n",
    "    Efficiently cleans, tokenizes, lemmatizes, and implements customized\n",
    "    bigrams on a list of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        original_tweets (required, pd.Series)\n",
    "    \n",
    "    Returns:\n",
    "        cleaned, tokenized tweets (np.array)\n",
    "    \"\"\"\n",
    "    tweet_array = original_tweets.to_numpy()\n",
    "\n",
    "    all_words = list(words.words('en')) + custom_words\n",
    "    stop_words = set(list(stopwords.words('english')) + custom_stop_words)\n",
    "    \n",
    "    for _, new in bigrams:\n",
    "        all_words.append(new)\n",
    "\n",
    "    all_words = set(all_words)\n",
    "    print(\"num words: \", len(all_words))\n",
    "    print(\"num stop words: \", len(stop_words))\n",
    "    \n",
    "    clean_tweets = [tokenize(tweet, all_words, stop_words) for tweet in tweet_array]\n",
    "    \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "revised-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236120\n",
      "num stop words:  396\n",
      "CPU times: user 39.5 s, sys: 103 ms, total: 39.6 s\n",
      "Wall time: 39.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['tweet'] = clean_and_tokenize(data.original)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "studied-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60607, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_tokens'] = data['tweet'].str.count(' ') + 1\n",
    "\n",
    "mask = data['num_tokens'] >= 5\n",
    "data_minlen = data[mask]\n",
    "data_minlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Trump Tweets 32008\n",
      "\n",
      " Biden Tweets: 28599\n"
     ]
    }
   ],
   "source": [
    "mask = (data_minlen.trump == 0) & (data_minlen.biden == 1)\n",
    "biden = data_minlen[mask]\n",
    "mask = (data_minlen.trump ==1) & (data_minlen.biden == 0)\n",
    "trump = data_minlen[mask]\n",
    "\n",
    "print(f\"\\n Trump Tweets {len(trump)}\\n\\n Biden Tweets: {len(biden)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-tyler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"pickle/n2_tokenized_eff.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90461</th>\n",
       "      <td>To the disgusting people stealing Biden signs in Arlington VA- if your candidate is so great, why do you have to destroy the signs of the opposition?  I hope you are caught &amp;amp; prosecuted.</td>\n",
       "      <td>disgusting stealing sign candidate destroy sign opposition caught</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47902</th>\n",
       "      <td>@realDonaldTrump Trump nos odia.  Él no escribió esto.  Trump solo habla nazi.  Trump es la persona más malvada de Estados Unidos.</td>\n",
       "      <td>no e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73489</th>\n",
       "      <td>This election means so much to me as others Lije me. Silent no more just put my trumps signs out in my neighborhood that doesn’t allow signs.  Don’t care. God bless us ALL</td>\n",
       "      <td>mean silent trump sign neighborhood allow sign care godbless u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74877</th>\n",
       "      <td>The scene at the municipal airport in Kenosha, Wis. where Trump is about to address the crowd.   As of 11/2, about 5 new people every day are hospitalized with COVID in Kenosha County, with 23% of new tests coming back positive. At least 89 people here have died in the pandemic.</td>\n",
       "      <td>scene municipal airport wi address crowd covid county test coming positive least pandemic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71455</th>\n",
       "      <td>#PANDUMMY (BECAUSE HE'S DUMB ABOUT EVERYTHING) TRUMP claims his CDC director was wrong on vaccines and says he got confused  https://t.co/GBwwljcY1x 02 #VoteEarly</td>\n",
       "      <td>he dumb claim vaccine say confused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39059</th>\n",
       "      <td>Good Luck, Dear Lady Gaga, #Biden, Hey Friends, #Vote #BidenHarris2020, Hugs From BRAZIL !!</td>\n",
       "      <td>luck dear lady hey friend vote hug brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>@nodank_ But Biden will win in a landslide. :) Facts and wants can vary I suppose.</td>\n",
       "      <td>landslide fact want vary suppose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59878</th>\n",
       "      <td>Hillary had 3% lead in last days which was within the MOE. No way Trump wins unless he cheats and that is certainly possible</td>\n",
       "      <td>hillaryclinton lead day within win unless cheat certainly possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21346</th>\n",
       "      <td>Imagine how AMAZING it will be to have Sen @ossoff, Sen @ReverendWarnock President @JoeBiden and Madam Vice President @KamalaHarris!!!!!!! #vote for change!!</td>\n",
       "      <td>amazing sen sen madam vicepresident vote change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77651</th>\n",
       "      <td>@thehill @marcorubio Now, Marco is applauding a Trump caravan accused of vehicular intimidation serious enough to warrant FBI scrutiny. He's joined the thugs of law &amp;amp; order.</td>\n",
       "      <td>marco caravan accused vehicular intimidation serious enough warrant scrutiny he thug law</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                      original  \\\n",
       "90461                                                                                           To the disgusting people stealing Biden signs in Arlington VA- if your candidate is so great, why do you have to destroy the signs of the opposition?  I hope you are caught &amp; prosecuted.   \n",
       "47902                                                                                                                                                       @realDonaldTrump Trump nos odia.  Él no escribió esto.  Trump solo habla nazi.  Trump es la persona más malvada de Estados Unidos.   \n",
       "73489                                                                                                              This election means so much to me as others Lije me. Silent no more just put my trumps signs out in my neighborhood that doesn’t allow signs.  Don’t care. God bless us ALL   \n",
       "74877  The scene at the municipal airport in Kenosha, Wis. where Trump is about to address the crowd.   As of 11/2, about 5 new people every day are hospitalized with COVID in Kenosha County, with 23% of new tests coming back positive. At least 89 people here have died in the pandemic.   \n",
       "71455                                                                                                                       #PANDUMMY (BECAUSE HE'S DUMB ABOUT EVERYTHING) TRUMP claims his CDC director was wrong on vaccines and says he got confused  https://t.co/GBwwljcY1x 02 #VoteEarly   \n",
       "...                                                                                                                                                                                                                                                                                        ...   \n",
       "39059                                                                                                                                                                                              Good Luck, Dear Lady Gaga, #Biden, Hey Friends, #Vote #BidenHarris2020, Hugs From BRAZIL !!   \n",
       "11558                                                                                                                                                                                                       @nodank_ But Biden will win in a landslide. :) Facts and wants can vary I suppose.   \n",
       "59878                                                                                                                                                             Hillary had 3% lead in last days which was within the MOE. No way Trump wins unless he cheats and that is certainly possible   \n",
       "21346                                                                                                                            Imagine how AMAZING it will be to have Sen @ossoff, Sen @ReverendWarnock President @JoeBiden and Madam Vice President @KamalaHarris!!!!!!! #vote for change!!   \n",
       "77651                                                                                                        @thehill @marcorubio Now, Marco is applauding a Trump caravan accused of vehicular intimidation serious enough to warrant FBI scrutiny. He's joined the thugs of law &amp; order.   \n",
       "\n",
       "                                                                                           tweet  \n",
       "90461                          disgusting stealing sign candidate destroy sign opposition caught  \n",
       "47902                                                                                       no e  \n",
       "73489                             mean silent trump sign neighborhood allow sign care godbless u  \n",
       "74877  scene municipal airport wi address crowd covid county test coming positive least pandemic  \n",
       "71455                                                         he dumb claim vaccine say confused  \n",
       "...                                                                                          ...  \n",
       "39059                                                  luck dear lady hey friend vote hug brazil  \n",
       "11558                                                           landslide fact want vary suppose  \n",
       "59878                         hillaryclinton lead day within win unless cheat certainly possible  \n",
       "21346                                            amazing sen sen madam vicepresident vote change  \n",
       "77651   marco caravan accused vehicular intimidation serious enough warrant scrutiny he thug law  \n",
       "\n",
       "[15 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['original', 'tweet']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geological-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/tweets_df_5000tw.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confused-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236120\n",
      "num stop words:  396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tweet votingrights continuous breakdown']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'tweet tokenize me please mr. biden helloaskldjalksfj I  pence    voting rights am asking for a favor continuous breakdown American Americans'\n",
    "\n",
    "clean_and_tokenize(pd.Series(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "growing-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organization'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "lemm.lemmatize('organizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brief-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/n2_tokenized_min4.pick\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
