{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/balanced_nov2_tweets.pick\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>1323379284434669568</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:39:43</td>\n",
       "      <td>2820503362</td>\n",
       "      <td>artistacriseida</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323414585995526144</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>1312487180258820096</td>\n",
       "      <td>annapieters17</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323414585232293888</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>2335763630</td>\n",
       "      <td>kylechwatt</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "181142  1323379284434669568 2020-11-02  21:39:43           2820503362   \n",
       "0       1323414585995526144 2020-11-02  23:59:59  1312487180258820096   \n",
       "4       1323414585232293888 2020-11-02  23:59:59           2335763630   \n",
       "\n",
       "               username hashtags  trump  biden  \\\n",
       "181142  artistacriseida       []  False   True   \n",
       "0         annapieters17       []  False   True   \n",
       "4            kylechwatt       []  False   True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                        original  \n",
       "181142  All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾  \n",
       "0                                                                                                                  @FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.  \n",
       "4                                                        @The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data['original'] = data.tweet\n",
    "data.drop(columns='tweet', inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Pre-Processing Pipeline\n",
    "\n",
    "Now it's time to tokenize our tweets. Here are our pre-processing steps:\n",
    "* Remove URLs\n",
    "* Remove Twitter handles\n",
    "* Remove numbers\n",
    "* Convert to lowercase\n",
    "* Remove punctuation\n",
    "* Remove repeated letters so spell check will work ('aaaaand' -> 'aand')\n",
    "* Remove non-English words\n",
    "* Remove stop words\n",
    "\n",
    "Since we're working with so many different words, I've chosen to use **lemmatization** instead of stemming for two reasons:\n",
    "1. Lemmatization accurately reduces words to true meaning\n",
    "2. Inxreased word reduction (handles synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "motivated-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download() # must run first time (download 'popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sweet-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom word dictionaries\n",
    "from more_words import more_words as custom_words\n",
    "from stop_words import stop_words as custom_stop_words\n",
    "from bigrams import bigrams\n",
    "\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    \"\"\"Pre-processing pipeline.\"\"\"\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"u\\.s\\. \", \"usa\", tweet)\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r'\\w*\\d\\w*', ' ', tweet)\n",
    "    tweet = re.sub(r'\\.{2,6}', ' ', tweet)\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    tweet = re.sub(r\"([a-z])\\1{2,5}\", r'\\1', tweet)\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    \n",
    "    for old, new in bigrams:\n",
    "        tweet = re.sub(old, new, tweet) # ex: ('white house', 'whitehouse')\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "def tokenize(tweet, all_words, stop_words):\n",
    "    \"\"\"\n",
    "    Returns all of the tokens in a cleaned tweet\n",
    "    Parameters:\n",
    "        - tweet (Series, required)\n",
    "        - stop_words (set, required)\n",
    "        - all_words (set, required) \n",
    "        \n",
    "    Note:\n",
    "        - any words not included in all_words here will be\n",
    "          removed from tokens (including bigrams)\n",
    "    \"\"\"\n",
    "    \n",
    "    tweet = clean_tweet(tweet)\n",
    "    \n",
    "    twt = TweetTokenizer()    \n",
    "    lemm = WordNetLemmatizer()  \n",
    "    # lemmatize tokens & remove stop words\n",
    "    tokens = [lemm.lemmatize(token) for token in twt.tokenize(tweet) if token not in stop_words]\n",
    "    # only include words that are in our customized list of words\n",
    "    tokens = [token for token in tokens if token in all_words]\n",
    "    combined_tokens = ' '.join(tokens)\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "def clean_and_tokenize(original_tweets):\n",
    "    \"\"\"\n",
    "    Efficiently cleans, tokenizes, lemmatizes, and implements customized\n",
    "    bigrams on a list of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        original_tweets (required, pd.Series)\n",
    "    \n",
    "    Returns:\n",
    "        cleaned, tokenized tweets (np.array)\n",
    "    \"\"\"\n",
    "    tweet_array = original_tweets.to_numpy()\n",
    "\n",
    "    all_words = list(words.words('en')) + custom_words\n",
    "    stop_words = set(list(stopwords.words('english')) + custom_stop_words)\n",
    "    \n",
    "    for _, new in bigrams:\n",
    "        all_words.append(new)\n",
    "\n",
    "    all_words = set(all_words)\n",
    "    print(\"num words: \", len(all_words))\n",
    "    print(\"num stop words: \", len(stop_words))\n",
    "    \n",
    "    clean_tweets = [tokenize(tweet, all_words, stop_words) for tweet in tweet_array]\n",
    "    \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informative-congo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236109\n",
      "num stop words:  388\n",
      "CPU times: user 47.8 s, sys: 100 ms, total: 47.9 s\n",
      "Wall time: 48.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['tweet'] = clean_and_tokenize(data.original)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accepted-albany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71156, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_tokens'] = data['tweet'].str.count(' ') + 1\n",
    "\n",
    "mask = data['num_tokens'] >= 5\n",
    "data_minlen = data[mask]\n",
    "data_minlen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspected-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Trump Tweets 36878\n",
      "\n",
      " Biden Tweets: 34278\n"
     ]
    }
   ],
   "source": [
    "mask = (data_minlen.trump == 0) & (data_minlen.biden == 1)\n",
    "biden = data_minlen[mask]\n",
    "mask = (data_minlen.trump ==1) & (data_minlen.biden == 0)\n",
    "trump = data_minlen[mask]\n",
    "\n",
    "print(f\"\\n Trump Tweets {len(trump)}\\n\\n Biden Tweets: {len(biden)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-raising",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"pickle/n2_tokenized_eff.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "egyptian-surface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5712</th>\n",
       "      <td>@SVNewsAlerts WOW, JUST WOW...WHAT WE HAVE HERE IS THERE DIALABOLITICAL PLAN...IF BIDEN LAST 3 MONTHS I WILL BE VERY SURPRISED...!!!</td>\n",
       "      <td>wow wow plan joebiden month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Eliazar Cisneros, is the man who rammed the white car in the Biden bus video. I want to know why @TexasHwyPatrol is not doing their job to stop this domestic terrorist! @fbi @SecretService need to investigate this matter. #DomesticTerrorist</td>\n",
       "      <td>white car joebiden bus video job stop domestic terrorist investigate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11334</th>\n",
       "      <td>Of course not. I do however know some people stupid enough to vote for Biden. So sad...</td>\n",
       "      <td>course however stupid enough votejoebiden sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8293</th>\n",
       "      <td>Joe Biden a corrupt pedophile with dementia who incites hatred and violence. He's typical of his voters.</td>\n",
       "      <td>joebiden corrupt dementia hatred violence he typical voter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80782</th>\n",
       "      <td>‘Presidents Don’t Determine Who Gets to Vote,’ Biden Says  https://t.co/u4KjHNgmCF</td>\n",
       "      <td>president determine get vote joebiden say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>@EarnhardtFan9 @jaketapper ...I don't even like Trump. And that didn't even begin to answer the question I asked. So you're either a bot or an idiot. Either way, enjoy the block. I know I will.</td>\n",
       "      <td>donaldtrump begin answer question either bot idiot either enjoy block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43395</th>\n",
       "      <td>@GOP @realDonaldTrump REMEMBER THESE TRUMP LIES FROM 2016? \"Cutting Taxes\" - FAILED  \"GOP is not just planning to increase taxes on Americans. The increase has already been signed, sealed &amp;amp; delivered in the '17 Tax Cuts &amp;amp; Jobs Act-delayed tax increase dressed up as a tax cut\"  https://t.co/oLTEIkO6su</td>\n",
       "      <td>donaldtrump remember trumplies cutting tax raisetax increase sealed tax cut job tax increase dressed tax cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35093</th>\n",
       "      <td>Furia en la Casa Blanca con el médico Fauci por alabar postura de Biden sobre Covid-19  #2Nov   #FelizLunes    https://t.co/KyuDUT7viD</td>\n",
       "      <td>anthonyfauci joebiden covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82117</th>\n",
       "      <td>@Breaking911 @FLOTUS Beijing Biden’s 47 years of political fraud and corruption come to end Nov. 4th.</td>\n",
       "      <td>joebiden year political fraud corruption end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83743</th>\n",
       "      <td>@Mymichelle519 @day_graeme @prageru @DouglasKMurray @DennisPrager Hahahah as opposed to Trump supporters?????!!!!!</td>\n",
       "      <td>opposed trumpsupporter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                    original  \\\n",
       "5712                                                                                                                                                                                    @SVNewsAlerts WOW, JUST WOW...WHAT WE HAVE HERE IS THERE DIALABOLITICAL PLAN...IF BIDEN LAST 3 MONTHS I WILL BE VERY SURPRISED...!!!   \n",
       "847                                                                         Eliazar Cisneros, is the man who rammed the white car in the Biden bus video. I want to know why @TexasHwyPatrol is not doing their job to stop this domestic terrorist! @fbi @SecretService need to investigate this matter. #DomesticTerrorist   \n",
       "11334                                                                                                                                                                                                                                Of course not. I do however know some people stupid enough to vote for Biden. So sad...   \n",
       "8293                                                                                                                                                                                                                Joe Biden a corrupt pedophile with dementia who incites hatred and violence. He's typical of his voters.   \n",
       "80782                                                                                                                                                                                                                                     ‘Presidents Don’t Determine Who Gets to Vote,’ Biden Says  https://t.co/u4KjHNgmCF   \n",
       "...                                                                                                                                                                                                                                                                                                                      ...   \n",
       "7616                                                                                                                       @EarnhardtFan9 @jaketapper ...I don't even like Trump. And that didn't even begin to answer the question I asked. So you're either a bot or an idiot. Either way, enjoy the block. I know I will.   \n",
       "43395  @GOP @realDonaldTrump REMEMBER THESE TRUMP LIES FROM 2016? \"Cutting Taxes\" - FAILED  \"GOP is not just planning to increase taxes on Americans. The increase has already been signed, sealed &amp; delivered in the '17 Tax Cuts &amp; Jobs Act-delayed tax increase dressed up as a tax cut\"  https://t.co/oLTEIkO6su   \n",
       "35093                                                                                                                                                                                 Furia en la Casa Blanca con el médico Fauci por alabar postura de Biden sobre Covid-19  #2Nov   #FelizLunes    https://t.co/KyuDUT7viD   \n",
       "82117                                                                                                                                                                                                                  @Breaking911 @FLOTUS Beijing Biden’s 47 years of political fraud and corruption come to end Nov. 4th.   \n",
       "83743                                                                                                                                                                                                     @Mymichelle519 @day_graeme @prageru @DouglasKMurray @DennisPrager Hahahah as opposed to Trump supporters?????!!!!!   \n",
       "\n",
       "                                                                                                              tweet  \n",
       "5712                                                                                    wow wow plan joebiden month  \n",
       "847                                            white car joebiden bus video job stop domestic terrorist investigate  \n",
       "11334                                                                 course however stupid enough votejoebiden sad  \n",
       "8293                                                     joebiden corrupt dementia hatred violence he typical voter  \n",
       "80782                                                                     president determine get vote joebiden say  \n",
       "...                                                                                                             ...  \n",
       "7616                                          donaldtrump begin answer question either bot idiot either enjoy block  \n",
       "43395  donaldtrump remember trumplies cutting tax raisetax increase sealed tax cut job tax increase dressed tax cut  \n",
       "35093                                                                                   anthonyfauci joebiden covid  \n",
       "82117                                                                  joebiden year political fraud corruption end  \n",
       "83743                                                                                        opposed trumpsupporter  \n",
       "\n",
       "[15 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['original', 'tweet']].sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geological-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/tweets_df_5000tw.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "confused-competition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words:  236109\n",
      "num stop words:  388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tweet joebiden mikepence votingrights continuous breakdown']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = 'tweet tokenize me please mr. biden helloaskldjalksfj I  pence    voting rights am asking for a favor continuous breakdown American Americans'\n",
    "\n",
    "clean_and_tokenize(pd.Series(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "growing-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'organization'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = WordNetLemmatizer()\n",
    "lemm.lemmatize('organizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "brief-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/n2_tokenized_min4.pick\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
