{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "authorized-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-holiday",
   "metadata": {},
   "source": [
    "**Kelsey 1-1**\n",
    "\n",
    "- cleaning\n",
    "    - preprocessing until comfortable with words\n",
    "   \n",
    "- sentiment analysis on all tweets\n",
    "    - don't need to do any splitting at this stage\n",
    "    - TextBlob & VaderSentiment first, spacy if the results aren't as expected\n",
    "    \n",
    "- topic modeling\n",
    "    - decide: use all tweets (all topics) at once\n",
    "        - start here\n",
    "        - then can use these as features in the dataFrame and do splitting here\n",
    "    - or: split to trump/biden - then bot/not bot for each\n",
    "    - point here is there are multiple ways to split it\n",
    "        - no right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "integral-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inner-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"pickle/balanced_nov2_tweets.pick\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'time', 'user_id', 'username', 'tweet', 'hashtags',\n",
       "       'trump', 'biden'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patent-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69839"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.username.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94653</th>\n",
       "      <td>1323398004955439105</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>22:54:06</td>\n",
       "      <td>1238549038082842624</td>\n",
       "      <td>cameron13107534</td>\n",
       "      <td>@Eliesje3 @FLOTUS @realDonaldTrump Like Trump likes to tell the immigrants who come here...Go back to where she came from.</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72815</th>\n",
       "      <td>1323393189965869056</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>22:34:58</td>\n",
       "      <td>65500701</td>\n",
       "      <td>nad_man89</td>\n",
       "      <td>@KellyScaletta @BetoORourke It all started with Beto biden and whataburger .</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>1323412509072760834</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:51:44</td>\n",
       "      <td>822988306443108352</td>\n",
       "      <td>holme_susan</td>\n",
       "      <td>Trump is encouraging anti-democratic violence — but don't let that stop you   https://t.co/MQkcvX6L1d</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id       date      time              user_id  \\\n",
       "94653  1323398004955439105 2020-11-02  22:54:06  1238549038082842624   \n",
       "72815  1323393189965869056 2020-11-02  22:34:58             65500701   \n",
       "9462   1323412509072760834 2020-11-02  23:51:44   822988306443108352   \n",
       "\n",
       "              username  \\\n",
       "94653  cameron13107534   \n",
       "72815        nad_man89   \n",
       "9462       holme_susan   \n",
       "\n",
       "                                                                                                                            tweet  \\\n",
       "94653  @Eliesje3 @FLOTUS @realDonaldTrump Like Trump likes to tell the immigrants who come here...Go back to where she came from.   \n",
       "72815                                                @KellyScaletta @BetoORourke It all started with Beto biden and whataburger .   \n",
       "9462                        Trump is encouraging anti-democratic violence — but don't let that stop you   https://t.co/MQkcvX6L1d   \n",
       "\n",
       "      hashtags  trump  biden  \n",
       "94653       []   True  False  \n",
       "72815       []  False   True  \n",
       "9462        []   True  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-muscle",
   "metadata": {},
   "source": [
    "Now let's create a subset, containing the same amount of Trump tweets as Biden tweets. We will exclude tweets that mention both candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>1323379284434669568</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>21:39:43</td>\n",
       "      <td>2820503362</td>\n",
       "      <td>artistacriseida</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323414585995526144</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>1312487180258820096</td>\n",
       "      <td>annapieters17</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1323414585232293888</td>\n",
       "      <td>2020-11-02</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>2335763630</td>\n",
       "      <td>kylechwatt</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>@The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id       date      time              user_id  \\\n",
       "181142  1323379284434669568 2020-11-02  21:39:43           2820503362   \n",
       "0       1323414585995526144 2020-11-02  23:59:59  1312487180258820096   \n",
       "4       1323414585232293888 2020-11-02  23:59:59           2335763630   \n",
       "\n",
       "               username hashtags  trump  biden  \\\n",
       "181142  artistacriseida       []  False   True   \n",
       "0         annapieters17       []  False   True   \n",
       "4            kylechwatt       []  False   True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                        original  \n",
       "181142  All these articles showing that Biden is in the lead.... IGNORE THAT AND STILL GO VOTE. All of these maps showing information that may or may not be correct won’t matter on Election Day. Hillary was also in the lead last election, just do your part.   ⁽ᶠᵘᶜᵏ ᵗʳᵘᵐᵖ⁾  \n",
       "0                                                                                                                  @FoxNews Lady Gaga’s a nobody. Can’t figure out her own life and can’t even see nobody can help Biden. He’s out of the game from the day he gets in the game.  \n",
       "4                                                        @The_Grupp “It is purely a fortuity that this isn’t one of the great mass casualty events in American history,” Ron Klain, who was Biden’s chief of staff at the time, said of H1N1 in 2019.”   https://t.co/Umi317supK  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data['original'] = data.tweet\n",
    "data.drop(columns='tweet', inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "welsh-highway",
   "metadata": {},
   "source": [
    "## Pre-Processing Pipeline\n",
    "\n",
    "Now it's time to tokenize our tweets. Here are our pre-processing steps:\n",
    "* Remove URLs\n",
    "* Remove Twitter handles\n",
    "* Remove numbers\n",
    "* Convert to lowercase\n",
    "* Remove punctuation\n",
    "* Remove repeated letters so spell check will work ('aaaaand' -> 'aand')\n",
    "* Remove non-English words\n",
    "* Remove stop words\n",
    "\n",
    "Since we're working with so many different words, I've chosen to use **lemmatization** instead of stemming for two reasons:\n",
    "1. Lemmatization accurately reduces words to true meaning\n",
    "2. Inxreased word reduction (handles synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "democratic-connection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is sample text joe_biden donald_trump'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing these before putting them in func\n",
    "\n",
    "\n",
    "tweet = 'this is ! SAMPLE text...    @joebiden @donaldtrump #2020electionusa #2020ELECTIONUSA'\n",
    "\n",
    "tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "# remove numbers\n",
    "tweet = re.sub('\\w*\\d\\w*', ' ', tweet)\n",
    "# replace '...' with ' '\n",
    "tweet = re.sub('\\.{2,6}', ' ', tweet)\n",
    "# remove punctuation\n",
    "tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "# convert to lowercase\n",
    "tweet = tweet.lower()\n",
    "\n",
    "# and other popular campaign phrases\n",
    "tweet = re.sub(r\"make america great again\", \"maga\", tweet)\n",
    "tweet = re.sub(r\"makeamericagreatagain\", \"maga\", tweet)\n",
    "\n",
    "# remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "tweet = re.sub(r\"([a-z])\\1{2,}\", r'\\1', tweet)\n",
    "# replace consecutive spaces with one\n",
    "tweet = ' '.join(tweet.split())\n",
    "\n",
    "# remove spaces in candidate names\n",
    "tweet = re.sub(r\"joebiden\", \"joe_biden\", tweet)\n",
    "tweet = re.sub(r\"kamalaharris\", \"kamala_harris\", tweet)\n",
    "tweet = re.sub(r\"donaldtrump\", \"donald_trump\", tweet)\n",
    "tweet = re.sub(r\"mikepence\", \"mike_pence\", tweet)\n",
    "tweet = re.sub(r\"joe biden\", \"joe_biden\", tweet)\n",
    "tweet = re.sub(r\"kamala harris\", \"kamala_harris\", tweet)\n",
    "tweet = re.sub(r\"donald trump\", \"donald_trump\", tweet)\n",
    "tweet = re.sub(r\"mike pence\", \"mike_pence\", tweet)\n",
    "# replace 'biden' with 'joebiden' (do for all candidates)\n",
    "tweet = re.sub(r\"\\bbiden\\b\", \"joe_biden\", tweet)\n",
    "tweet = re.sub(r\"\\bpence\\b\", \"mike_pence\", tweet)\n",
    "tweet = re.sub(r\"\\bharris\\b\", \"kamala_harris\", tweet)\n",
    "tweet = re.sub(r\"\\btrump\\b\", \"donald_trump\", tweet)\n",
    "# other replacements\n",
    "tweet = re.sub(r\"attorney general\", \"attorney_general\", tweet)\n",
    "tweet = re.sub(r\"white house\", \"white_house\", tweet)\n",
    "\n",
    "tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autocorrect import Speller # TOO SLOW...TRY PYSPELLCHECKER\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "    # pre-processing pipeline\n",
    "    \n",
    "    # remove urls\n",
    "    tweet = re.sub(r\"https?:\\/\\/\\S+\", \"\", tweet)\n",
    "    # remove numbers\n",
    "    tweet = re.sub('\\w*\\d\\w*', ' ', tweet)\n",
    "    # remove punctuation\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    # convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # remove repeated letters so spell check will work (ex: 'aaaand' --> 'aand')\n",
    "    tweet = re.sub(r\"([a-z])\\1{2,5}\", r'\\1', tweet)\n",
    "    # replace consecutive spaces with one\n",
    "    tweet = ' '.join(tweet.split())\n",
    "\n",
    "    # remove spaces in candidate names\n",
    "    tweet = re.sub(r\"joebiden\", \"joe_biden\", tweet)\n",
    "    tweet = re.sub(r\"kamalaharris\", \"kamala_harris\", tweet)\n",
    "    tweet = re.sub(r\"donaldtrump\", \"donald_trump\", tweet)\n",
    "    tweet = re.sub(r\"mikepence\", \"mike_pence\", tweet)\n",
    "    tweet = re.sub(r\"joe biden\", \"joe_biden\", tweet)\n",
    "    tweet = re.sub(r\"kamala harris\", \"kamala_harris\", tweet)\n",
    "    tweet = re.sub(r\"donald trump\", \"donald_trump\", tweet)\n",
    "    tweet = re.sub(r\"mike pence\", \"mike_pence\", tweet)\n",
    "    # replace 'biden' with 'joebiden' (do for all candidates)\n",
    "    tweet = re.sub(r\"\\bbiden\\b\", \"joe_biden\", tweet)\n",
    "    tweet = re.sub(r\"\\bpence\\b\", \"mike_pence\", tweet)\n",
    "    tweet = re.sub(r\"\\bharris\\b\", \"kamala_harris\", tweet)\n",
    "    tweet = re.sub(r\"\\btrump\\b\", \"donald_trump\", tweet)\n",
    "    # other replacements\n",
    "    tweet = re.sub(r\"attorney general\", \"attorney_general\", tweet)\n",
    "    tweet = re.sub(r\"white house\", \"white_house\", tweet)\n",
    "    tweet = re.sub(r\"make america great again\", \"maga\", tweet)\n",
    "    tweet = re.sub(r\"makeamericagreatagain\", \"maga\", tweet)\n",
    "\n",
    "    return tweet\n",
    "\n",
    "def tweet_tokenize(tweet, more_stop=None, more_words=None):\n",
    "    \"\"\"Get all of the tokens in a set of tweets.\n",
    "    \n",
    "    Parameters:\n",
    "        - tweets (Series, required)\n",
    "        \n",
    "        - more_stop (List, optional): additional stop words to exclude\n",
    "        \n",
    "        - more_words (List, optional): additional words to INCLUDE in dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    # identify election-related words that \n",
    "    more_words = ['trump', 'biden', 'maga', 'bidenharris', \n",
    "                  'kamala', 'pence', 'harris', 'mike',\n",
    "                  'bidenharris2020', 'trumppence', 'white_house',\n",
    "                  'trumppence2020', 'usa', 'election2020',\n",
    "                  'ivoted', 'joe_biden', 'realdonaldtrump',\n",
    "                  'donald_trump', 'attorney_general',\n",
    "                  'mike_pence', 'kamala_harris']\n",
    "    \n",
    "    all_words = list(words.words()) + more_words\n",
    "    all_words = set(all_words)\n",
    "    \n",
    "    twt = TweetTokenizer()\n",
    "    tokens = [token for token in twt.tokenize(tweet) if token in all_words]\n",
    "    \n",
    "    # lemmatize text\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    tokens = [lemm.lemmatize(token) for token in tokens]\n",
    "#     spell = Speller(lang='en')\n",
    "#     tokens = [spell(t) for t in tokens]\n",
    "\n",
    "    combined_tokens = ' '.join(tokens)\n",
    "\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['original'].map(tweet_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"pickle/n2_tokenized.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_pickle(\"pickle/tweets_df_5000tw.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-binary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-louis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-europe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-failing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-conference",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
