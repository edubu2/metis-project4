{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tribal-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defensive-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must uncomment & run the first time to DOWNLOAD NLTK data\n",
    "# I used package identifier 'popular'\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fantastic-tuesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(879311, 38)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"pickle/df_t_raw.pick\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loaded-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trump'] = df['trump'].astype(int)\n",
    "df['biden'] = df['biden'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "analyzed-writer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>biden</th>\n",
       "      <th>trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1312904496507432961</td>\n",
       "      <td>1312835414873399297</td>\n",
       "      <td>2020-10-04 23:56:39 UTC</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>23:56:39</td>\n",
       "      <td>0</td>\n",
       "      <td>1181366088099123202</td>\n",
       "      <td>oknyork1</td>\n",
       "      <td>OkNYork</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Back_dafucup', 'name': 'Jenn...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>1312538964826365952</td>\n",
       "      <td>1312494005758783488</td>\n",
       "      <td>2020-10-03 23:44:09 UTC</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>23:44:09</td>\n",
       "      <td>0</td>\n",
       "      <td>1916249839</td>\n",
       "      <td>billy_cage</td>\n",
       "      <td>ùêôùê¢ppùê¢ùêßùê†ùê´ùê®ùêúùê§ùê¨ (Halo CE MacWorld Remake)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Truxillogical', 'name': 'Tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8008</th>\n",
       "      <td>1317611310323015681</td>\n",
       "      <td>1317610975068119047</td>\n",
       "      <td>2020-10-17 23:39:51 UTC</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>23:39:51</td>\n",
       "      <td>0</td>\n",
       "      <td>980824830613315584</td>\n",
       "      <td>datawookiee</td>\n",
       "      <td>√êR Plissken ESQ (unpaid intern for @ResitsTrump)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'ResitsTrump', 'name': 'Dr. K...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>1318334102097915904</td>\n",
       "      <td>1318334102097915904</td>\n",
       "      <td>2020-10-19 23:31:58 UTC</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>23:31:58</td>\n",
       "      <td>0</td>\n",
       "      <td>898759943393816576</td>\n",
       "      <td>americafirstmg</td>\n",
       "      <td>The DC Patriot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1321240167664001027</td>\n",
       "      <td>1321240167664001027</td>\n",
       "      <td>2020-10-27 23:59:38 UTC</td>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>23:59:38</td>\n",
       "      <td>0</td>\n",
       "      <td>356845993</td>\n",
       "      <td>brokenletter</td>\n",
       "      <td>brokenletter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10762</th>\n",
       "      <td>1314713465462849537</td>\n",
       "      <td>1314309141591138320</td>\n",
       "      <td>2020-10-09 23:44:51 UTC</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>23:44:51</td>\n",
       "      <td>0</td>\n",
       "      <td>1494105091</td>\n",
       "      <td>wendywamsley</td>\n",
       "      <td>wendy wamsley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'NikkiHaley', 'name': 'Nikki ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>1323050167319339013</td>\n",
       "      <td>1323050167319339013</td>\n",
       "      <td>2020-11-01 23:51:55 UTC</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>23:51:55</td>\n",
       "      <td>0</td>\n",
       "      <td>29989542</td>\n",
       "      <td>teresaxlynn10</td>\n",
       "      <td>Teresa üíõüíõ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>1315439486873079808</td>\n",
       "      <td>1315417973591547906</td>\n",
       "      <td>2020-10-11 23:49:48 UTC</td>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>23:49:48</td>\n",
       "      <td>0</td>\n",
       "      <td>27317649</td>\n",
       "      <td>leachtheteach</td>\n",
       "      <td>Andrew Leach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'realDonaldTrump', 'name': 'D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>1315440201477521409</td>\n",
       "      <td>1315327978553958400</td>\n",
       "      <td>2020-10-11 23:52:38 UTC</td>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>23:52:38</td>\n",
       "      <td>0</td>\n",
       "      <td>20778809</td>\n",
       "      <td>mimionthehoops</td>\n",
       "      <td>Mimi (wear 2 freakin' masks!)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'aerotycoon', 'name': 'AeroTy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>1313628906696605696</td>\n",
       "      <td>1313628906696605696</td>\n",
       "      <td>2020-10-06 23:55:12 UTC</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>23:55:12</td>\n",
       "      <td>0</td>\n",
       "      <td>57366686</td>\n",
       "      <td>fbellavia</td>\n",
       "      <td>Frank B.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id      conversation_id               created_at  \\\n",
       "1013   1312904496507432961  1312835414873399297  2020-10-04 23:56:39 UTC   \n",
       "4247   1312538964826365952  1312494005758783488  2020-10-03 23:44:09 UTC   \n",
       "8008   1317611310323015681  1317610975068119047  2020-10-17 23:39:51 UTC   \n",
       "12281  1318334102097915904  1318334102097915904  2020-10-19 23:31:58 UTC   \n",
       "242    1321240167664001027  1321240167664001027  2020-10-27 23:59:38 UTC   \n",
       "10762  1314713465462849537  1314309141591138320  2020-10-09 23:44:51 UTC   \n",
       "4549   1323050167319339013  1323050167319339013  2020-11-01 23:51:55 UTC   \n",
       "3844   1315439486873079808  1315417973591547906  2020-10-11 23:49:48 UTC   \n",
       "3542   1315440201477521409  1315327978553958400  2020-10-11 23:52:38 UTC   \n",
       "2782   1313628906696605696  1313628906696605696  2020-10-06 23:55:12 UTC   \n",
       "\n",
       "             date      time  timezone              user_id        username  \\\n",
       "1013   2020-10-04  23:56:39         0  1181366088099123202        oknyork1   \n",
       "4247   2020-10-03  23:44:09         0           1916249839      billy_cage   \n",
       "8008   2020-10-17  23:39:51         0   980824830613315584     datawookiee   \n",
       "12281  2020-10-19  23:31:58         0   898759943393816576  americafirstmg   \n",
       "242    2020-10-27  23:59:38         0            356845993    brokenletter   \n",
       "10762  2020-10-09  23:44:51         0           1494105091    wendywamsley   \n",
       "4549   2020-11-01  23:51:55         0             29989542   teresaxlynn10   \n",
       "3844   2020-10-11  23:49:48         0             27317649   leachtheteach   \n",
       "3542   2020-10-11  23:52:38         0             20778809  mimionthehoops   \n",
       "2782   2020-10-06  23:55:12         0             57366686       fbellavia   \n",
       "\n",
       "                                                   name place  ... user_rt_id  \\\n",
       "1013                                            OkNYork   NaN  ...        NaN   \n",
       "4247             ùêôùê¢ppùê¢ùêßùê†ùê´ùê®ùêúùê§ùê¨ (Halo CE MacWorld Remake)   NaN  ...        NaN   \n",
       "8008   √êR Plissken ESQ (unpaid intern for @ResitsTrump)   NaN  ...        NaN   \n",
       "12281                                    The DC Patriot   NaN  ...        NaN   \n",
       "242                                        brokenletter   NaN  ...        NaN   \n",
       "10762                                     wendy wamsley   NaN  ...        NaN   \n",
       "4549                                          Teresa üíõüíõ   NaN  ...        NaN   \n",
       "3844                                       Andrew Leach   NaN  ...        NaN   \n",
       "3542                      Mimi (wear 2 freakin' masks!)   NaN  ...        NaN   \n",
       "2782                                           Frank B.   NaN  ...        NaN   \n",
       "\n",
       "      user_rt retweet_id                                           reply_to  \\\n",
       "1013      NaN        NaN  [{'screen_name': 'Back_dafucup', 'name': 'Jenn...   \n",
       "4247      NaN        NaN  [{'screen_name': 'Truxillogical', 'name': 'Tru...   \n",
       "8008      NaN        NaN  [{'screen_name': 'ResitsTrump', 'name': 'Dr. K...   \n",
       "12281     NaN        NaN                                                 []   \n",
       "242       NaN        NaN                                                 []   \n",
       "10762     NaN        NaN  [{'screen_name': 'NikkiHaley', 'name': 'Nikki ...   \n",
       "4549      NaN        NaN                                                 []   \n",
       "3844      NaN        NaN  [{'screen_name': 'realDonaldTrump', 'name': 'D...   \n",
       "3542      NaN        NaN  [{'screen_name': 'aerotycoon', 'name': 'AeroTy...   \n",
       "2782      NaN        NaN                                                 []   \n",
       "\n",
       "      retweet_date  translate  trans_src  trans_dest biden trump  \n",
       "1013           NaN        NaN        NaN         NaN     1     0  \n",
       "4247           NaN        NaN        NaN         NaN     1     0  \n",
       "8008           NaN        NaN        NaN         NaN     1     1  \n",
       "12281          NaN        NaN        NaN         NaN     1     0  \n",
       "242            NaN        NaN        NaN         NaN     0     1  \n",
       "10762          NaN        NaN        NaN         NaN     0     1  \n",
       "4549           NaN        NaN        NaN         NaN     1     0  \n",
       "3844           NaN        NaN        NaN         NaN     1     1  \n",
       "3542           NaN        NaN        NaN         NaN     0     1  \n",
       "2782           NaN        NaN        NaN         NaN     1     1  \n",
       "\n",
       "[10 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-cleaner",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We'll start small by simply removing numbers & punctuation and converting each tweet to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fundamental-decline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@capriaaf @JoeBiden Plenty of results for #Tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Changinglenses @greger_mary @JRubinBlogger @G...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inside a Biden v. Trump marriage: \"you woke me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  trump  biden\n",
       "0  @capriaaf @JoeBiden Plenty of results for #Tru...      1      1\n",
       "1  @Changinglenses @greger_mary @JRubinBlogger @G...      0      1\n",
       "2  Inside a Biden v. Trump marriage: \"you woke me...      1      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only necessary columns\n",
    "data = df.loc[:,['tweet', 'trump', 'biden']]\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinguished-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_links = lambda x: re.sub(r\"https?:\\/\\/\\S+\", \"\", x)\n",
    "no_handles = lambda x: re.sub(r\"@[\\d\\w_]+\", \"\", x)\n",
    "alphanum = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pacific-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['original'] = data.tweet\n",
    "\n",
    "data['tweet'] = (data['tweet']\n",
    "                 .map(no_handles)\n",
    "                 .map(no_links)\n",
    "                 .map(punc_lower)\n",
    "                 .map(alphanum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-colony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>trump</th>\n",
       "      <th>biden</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plenty of results for  trumpcrimefamily and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@capriaaf @JoeBiden Plenty of results for #Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he left washington before impeachment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@Changinglenses @greger_mary @JRubinBlogger @G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inside a biden v  trump marriage   you woke me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Inside a Biden v. Trump marriage: \"you woke me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  trump  biden  \\\n",
       "0    plenty of results for  trumpcrimefamily and ...      1      1   \n",
       "1             he left washington before impeachment       0      1   \n",
       "2  inside a biden v  trump marriage   you woke me...      1      1   \n",
       "\n",
       "                                            original  \n",
       "0  @capriaaf @JoeBiden Plenty of results for #Tru...  \n",
       "1  @Changinglenses @greger_mary @JRubinBlogger @G...  \n",
       "2  Inside a Biden v. Trump marriage: \"you woke me...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "subjective-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tweets in which trump and biden are both named\n",
    "mask = (data.trump==1) & (data.biden==1)\n",
    "data = data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-nitrogen",
   "metadata": {},
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "manufactured-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "imposed-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all of you are the worst sort of faux  journalists    biased to the point of bigoted and totally in the tank for biden   if you had a shred of integrity you would look at the bobulinski allegations   but you don t   a deplorable phd      trump  '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tweet.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-endorsement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-devon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-brief",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-architect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-compromise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-morocco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-liberia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-asbestos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-telescope",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-southeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-analyst",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worthy-doctor",
   "metadata": {},
   "source": [
    "## NLTK Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fifth-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.trump == 0) & (df.biden == 1)\n",
    "biden_tweets = df[mask]['tweet']\n",
    "\n",
    "mask = (df.trump == 1) & (df.biden == 0)\n",
    "trump_tweets = df[mask]['tweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "portuguese-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351598,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stuffed-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352465,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "median-deployment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-ground",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "broke-minister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Not very surprising seeing as how she traveled...\n",
       "1    @LindseyGrahamSC @HerschelWalker Trumps little...\n",
       "2    @CalebPatriotKag üö® Trump is a Malta Mason serv...\n",
       "3    @birdmonger @Cernovich @realDonaldTrump Lots o...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fifteen-ordinance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    @Changinglenses @greger_mary @JRubinBlogger @G...\n",
       "6        Loving all these Republicans endorsing Biden.\n",
       "7    WATCH: 'Ballot chaser' boasts she got $55,000 ...\n",
       "8                   @JoeBiden  https://t.co/qTxhMODuIH\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tweets.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sound-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "puncs = [c for c in string.punctuation if c not in [\"#\", \":\"]]\n",
    "print(puncs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-plaza",
   "metadata": {},
   "source": [
    "ew - try pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "white-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autocorrect import Speller # TOO SLOW...TRY PYSPELLCHECKER\n",
    "def tweet_tokenize(tweets):\n",
    "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    tokens = [token for tweet in tweets for token in twt.tokenize(tweet)]\n",
    "    # combine stop words and punctuation\n",
    "    puncs = [c for c in string.punctuation if c not in [\"#\", \":\"]]\n",
    "    stop = stopwords.words(\"english\") + puncs + ['‚Äù']\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [ stemmer.stem(token) for tweet in tweets\n",
    "              for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "#     spell = Speller(lang='en')\n",
    "#     tokens = [spell(t) for t in tokens]\n",
    "\n",
    "    \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "neither-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tweet_tokenize(data.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "tight-chest",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'most_common'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-df6e192830b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'most_common'"
     ]
    }
   ],
   "source": [
    "tokens.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "treated-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-preliminary",
   "metadata": {},
   "source": [
    "Nice. Now we need to get these back into string form, and send them through a vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "interesting-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer(stop_words='english', max_df=0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "searching-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "backed-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = v.fit_transform(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "equivalent-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = pd.DataFrame(sparse.toarray(), columns=v.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "little-exploration",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-907d62988d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dense_cv_all_0218.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m   2861\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2863\u001b[0;31m         to_pickle(\n\u001b[0m\u001b[1;32m   2864\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2865\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol, storage_options)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# letting pickle write directly to the buffer is more memory-efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             pickle.dump(\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "dense.to_pickle(\"dense_cv_all_0218.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rapid-norman",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dense_cv_all_0218.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-3a56d6ee2321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dense_cv_all_0218.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dense_cv_all_0218.p'"
     ]
    }
   ],
   "source": [
    "dense = pd.read_pickle(\"dense_cv_all_0218.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-program",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-review",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-devices",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_words = ' '.join(trump_tokens)\n",
    "b_words = ' '.join(biden_tokens)\n",
    "t_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_trump = v.fit_transform(trump_tokens)\n",
    "v_biden = v.fit_transform(biden_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_trump = v_trump.toarray()\n",
    "va_biden = v_biden.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tv = pd.DataFrame(va_trump, columns=v.get_feature_names())\n",
    "df_bv = pd.DataFrame(va_biden, columns=v.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-klein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-movie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word = vectorizer.fit_transform(data.tweet)\n",
    "doc_word[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix = doc_word.toarray(1`)\n",
    "pd.DataFrame(X_matrix, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "arranged-nursing",
   "metadata": {},
   "source": [
    "**Kelsey 1-1**\n",
    "\n",
    "- cleaning\n",
    "    - preprocessing until comfortable with words\n",
    "   \n",
    "- sentiment analysis on all tweets\n",
    "    - don't need to do any splitting at this stage\n",
    "    - TextBlob & VaderSentiment first, spacy if the results aren't as expected\n",
    "    \n",
    "- topic modeling\n",
    "    - decide: use all tweets (all topics) at once\n",
    "        - start here\n",
    "        - then can use these as features in the dataFrame and do splitting here\n",
    "    - or: split to trump/biden - then bot/not bot for each\n",
    "    - point here is there are multiple ways to split it\n",
    "        - no right answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
